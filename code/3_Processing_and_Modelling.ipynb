{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df=pd.read_csv('..\\data\\canada_subreddit_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Modeling\n",
    "## Methodology\n",
    "\n",
    "Most of the processing is going to fall within the modeling itself, as we're going to define a custom stopword set and build a custom tokenizer that stems words to use. However, before we do that, I'd like to yank URL's out of the dataset, since we saw that they occur quite frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_url(text):\n",
    "    text = re.sub(r'https?:.*?\\s|www.*?\\s', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df['body_processed']= canada_df['body'].map(strip_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in our exploration that we identified a few top words shared between both subreddits that are outside the default stopword set. \"people\", \"like\", and \"canada\". Let's add this to our stopword set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords= stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords.extend(['people', 'like', 'canada'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess we probably should make the subreddit category binary. Let's do 1 for r/OnGuardForThee, and 0 for r/Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df['subreddit_bin']=canada_df['subreddit'].map(lambda x: 1 if x==\"onguardforthee\" else 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's build our tokenizer. It's going to do pretty much the same thing as the default tokenizer (remove punctuation, separate words), but it's also going to stem each word for consistency. Also we're going to keep question marks and exclamations marks as tokens, because I have a hunch that the number of occurances of them is reflective of argument style and could be useful information. We're going to use the Snowball stemmer because it anecdotally performs better than the Porter stemmer.\n",
    "\n",
    "Source acknowledgement: This is loosely modeled off of some of the stuff this guy did: http://jonathansoma.com/lede/algorithms-2017/classes/more-text-analysis/counting-and-stemming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowball_tokens(text):\n",
    "    text_processed = re.sub(r'[^A-Za-z0-9!*?*]', ' ', text).split()\n",
    "    tokens = [snow.stem(word) for word in text_processed]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowball_tokens2(text):\n",
    "    text_processed = re.sub(r'[^A-Za-z]', ' ', text).split()\n",
    "    tokens = [snow.stem(word) for word in text_processed]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we should tokenize our stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = [snow.stem(word) for word in custom_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "\n",
    "I'm keeping the default settings and am going to train on 75% and test on 25%. We've got 20,000 comments. I think that if we don't get results training on 15,000 and testing on 5000 I doubt we'll get them on any other ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=canada_df['body_processed']\n",
    "y=canada_df['subreddit_bin']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=1920)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Initial Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My hunch here is that CountVectorizer will give us more information that tf-idf, but might as well try both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cvec= Pipeline([('cvec', CountVectorizer(tokenizer=snowball_tokens, stop_words=custom_stopwords)),\n",
    "                     ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cvec_params = {'cvec__max_features': [3000, 5000, 7000],\n",
    "                   'cvec__ngram_range': [(1,1)],\n",
    "                   'lr__C':[0.1, 0.04, 0.01, 0.004,0.001]}\n",
    "gs_cvec = GridSearchCV(pipe_cvec, pipe_cvec_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done  72 out of  75 | elapsed:  3.1min remaining:    7.7s\n",
      "[Parallel(n_jobs=6)]: Done  75 out of  75 | elapsed:  3.3min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_cvec.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 7000, 'cvec__ngram_range': (1, 1), 'lr__C': 0.01}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6055981806264874"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6780976386309366"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998806207719857"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5816517578531308"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_cvec.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiousity, let's try this on comments that are greater than 50 words, with the idea that more words gives us more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_long = X_test[X_test.str.split().str.len() > 50]\n",
    "y_test_long = y_test[X_test.str.split().str.len() > 50]\n",
    "X_train_long = X_train[X_train.str.split().str.len() > 50]\n",
    "y_train_long = y_train[X_train.str.split().str.len() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 7000, 'cvec__ngram_range': (1, 1), 'lr__C': 0.01}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525377229080933"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345486111111112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're slightly more accurate at classifying long comments than short ones.\n",
    "\n",
    "Let's test a tfidf model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tfidf= Pipeline([('tfidf', TfidfVectorizer(tokenizer=snowball_tokens, stop_words=custom_stopwords)),\n",
    "                      ('lr', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "pipe_tfidf_params = {'tfidf__max_features': [7000,10_000, 15_000],\n",
    "                   'tfidf__ngram_range': [(1,1)],\n",
    "                   'lr__C':[0.1, 0.04, 0.01, 0.004,0.001]}\n",
    "gs_tfidf = GridSearchCV(pipe_tfidf, pipe_tfidf_params, cv=5, n_jobs=6, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done  75 out of  75 | elapsed:  3.5min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_tfidf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 0.1, 'tfidf__max_features': 7000, 'tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.621053287936973"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025736269567524"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.610624751293275"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074222668004012"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_tfidf.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7089163237311386"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6380208333333334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tfidf.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Conclusions:**\n",
    "\n",
    "The TFIDF vectorizer seems to be slightly outperforming the count vectorizer. But not by much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn= Pipeline([('cvec', TfidfVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords)),\n",
    "                    ('knn', KNeighborsClassifier())])\n",
    "\n",
    "pipe_knn_params = {'cvec__max_features': [5000],\n",
    "                   'cvec__ngram_range': [(1,1)],\n",
    "                   'knn__n_neighbors':[400,500,600]}\n",
    "gs_knn = GridSearchCV(pipe_knn, pipe_knn_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of  15 | elapsed:   17.6s remaining:   26.5s\n",
      "[Parallel(n_jobs=6)]: Done   8 out of  15 | elapsed:   35.3s remaining:   30.9s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  15 | elapsed:   35.7s remaining:   17.8s\n",
      "[Parallel(n_jobs=6)]: Done  12 out of  15 | elapsed:   35.9s remaining:    8.9s\n",
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:   48.8s finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_knn.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 5000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'knn__n_neighbors': 500}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6113684891193898"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6191297426373044"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5927178670911262"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5552900282424507"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_knn.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436213991769547"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6145833333333334"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Conclusions\n",
    "\n",
    "KNN gives worse results. Much less overfitting, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian\n",
    "\n",
    "### Gaussian/TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a Gaussian model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.toarray()\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gnb= Pipeline([('tfidf', TfidfVectorizer(tokenizer=snowball_tokens, stop_words=custom_stopwords)), ('dense', DenseTransformer()), ('gnb', GaussianNB())])\n",
    "pipe_gnb_params = {'tfidf__max_features': [2000,3000,4000,5000,6000],\n",
    "                    'tfidf__ngram_range':[(1,1), (2,2), (3,3)],}\n",
    "\n",
    "gs_gnb = GridSearchCV(pipe_gnb, pipe_gnb_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done  72 out of  75 | elapsed:  3.9min remaining:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done  75 out of  75 | elapsed:  4.0min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_gnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_features': 2000, 'tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5799278584970813"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gnb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6715972406473866"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575407879029049"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5765873015873016"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_gnb.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.658161865569273"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gnb.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998263888888888"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gnb.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Multinomial/CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb= Pipeline([('cv', CountVectorizer(stop_words=custom_stopwords)), ('mnb', MultinomialNB())])\n",
    "pipe_mnb_params = {'cv__max_features': [2000,3000,4000,5000,6000, 7000, 8000, 9000],\n",
    "                   'cv__tokenizer':[snowball_tokens, snowball_tokens2]\n",
    "                  }\n",
    "\n",
    "gs_mnb = GridSearchCV(pipe_mnb, pipe_mnb_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done  78 out of  80 | elapsed:  3.4min remaining:    5.1s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:  3.6min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_mnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 8000,\n",
       " 'cv__tokenizer': <function __main__.snowball_tokens2(text)>}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.621451275892861"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7174980100822499"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.624950258654994"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6368715083798883"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_mnb.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791495198902606"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423611111111112"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bnb= Pipeline([('cv', CountVectorizer(stop_words=custom_stopwords, binary=True)), \n",
    "                    ('bnb', BernoulliNB())])\n",
    "pipe_bnb_params = {'cv__max_features': [2000,3000,4000,5000,6000, 7000, 8000, 9000],\n",
    "                  'cv__tokenizer':[snowball_tokens, snowball_tokens2]}\n",
    "\n",
    "gs_bnb = GridSearchCV(pipe_bnb, pipe_bnb_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done  78 out of  80 | elapsed:  3.6min remaining:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:  3.7min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_bnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 4000,\n",
       " 'cv__tokenizer': <function __main__.snowball_tokens2(text)>}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190627763041557"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6840673918811356"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6136092319936332"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5731868131868132"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_bnb.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7377229080932785"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293402777777778"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Conclusions:\n",
    "- MNB seems to slightly outperform BNB in the general case. \n",
    "- Both significantly outperforms GNB.\n",
    "- However, BNB seems a bit less overfit.\n",
    "- The tokenizer that removes numbers and all punctuation seems to be outperforming the one that leaves the min.\n",
    "- MNB seems to like higher feature counts than BNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees, Forests, and Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I twiddled with bagging and tree models here for a bit, and didn't get any satisfactory results. Models typically were extremely overfit and didn't have great results.\n",
    "\n",
    "Let's try some random forest techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf=Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords, max_features=5000)), \n",
    "                  ('rf', RandomForestClassifier())])\n",
    "pipe_et=Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords, max_features=5000)), \n",
    "                  ('et', ExtraTreesClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5979701844447083"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe_rf, X_train, y_train, cv=5).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5984349032907963"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe_et, X_train, y_train, cv=5).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_features=5000,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'our', 'ourselv', 'you',\n",
       "                                             \"you'r\", \"you'v\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'your',\n",
       "                                             'yourself', 'yourselv', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             'she', 'her', 'her', 'herself',\n",
       "                                             'it', 'it', 'it', 'itself', ...],\n",
       "                                 tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                ('et', ExtraTreesClassifier())])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911780313080393"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955033824114604"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1517"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et[1].estimators_[10].get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try gridsearching over ExtraTrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_et2=Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords)), \n",
    "                  ('et', ExtraTreesClassifier())])\n",
    "\n",
    "pipe_et2_params = {'cv__max_features': [2500, 5000, 10_000],\n",
    "                   'et__max_depth':[10,50,100,500],\n",
    "                   'et__min_samples_split':[2,4,10,20],\n",
    "                   'et__min_samples_leaf':[1,5,10,20]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_et2 = GridSearchCV(pipe_et2, pipe_et2_params, cv=5, n_jobs=8, verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=8)]: Done   3 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done   8 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=8)]: Done  11 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=8)]: Done  13 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=8)]: Done  14 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=8)]: Done  15 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  19 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  20 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  21 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  22 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  23 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done  24 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  26 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  27 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  28 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  29 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  30 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  31 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  32 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done  35 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done  36 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done  37 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done  38 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done  39 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done  40 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=8)]: Done  41 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done  43 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done  44 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done  46 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done  47 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done  48 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done  49 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done  50 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done  51 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done  52 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done  53 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done  54 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done  55 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done  57 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done  58 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done  59 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done  60 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done  61 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  62 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  63 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  64 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  65 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  66 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  67 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  68 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  70 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  71 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=8)]: Done  72 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=8)]: Done  73 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  74 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  75 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  76 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  77 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  78 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  79 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  80 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=8)]: Done  81 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=8)]: Done  83 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  84 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  85 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  86 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  87 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  89 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  90 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  91 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  92 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  93 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  94 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  95 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done  96 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=8)]: Done  98 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=8)]: Done  99 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=8)]: Done 100 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=8)]: Done 101 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=8)]: Done 102 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=8)]: Done 103 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=8)]: Done 104 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=8)]: Done 105 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=8)]: Done 106 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=8)]: Done 107 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 108 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 109 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 110 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 111 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done 113 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=8)]: Done 114 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=8)]: Done 115 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=8)]: Done 116 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done 117 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done 118 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done 119 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done 120 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done 121 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=8)]: Done 122 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=8)]: Done 123 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=8)]: Done 124 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=8)]: Done 125 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=8)]: Done 126 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=8)]: Done 127 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=8)]: Done 128 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=8)]: Done 130 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=8)]: Done 131 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=8)]: Done 132 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=8)]: Done 133 tasks      | elapsed:  6.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 134 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=8)]: Done 135 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=8)]: Done 136 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=8)]: Done 137 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=8)]: Done 138 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=8)]: Done 139 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=8)]: Done 140 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=8)]: Done 141 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=8)]: Done 142 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=8)]: Done 143 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=8)]: Done 144 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=8)]: Done 145 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 147 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 148 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 149 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 150 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 151 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 152 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=8)]: Done 153 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=8)]: Done 154 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=8)]: Done 155 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=8)]: Done 156 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=8)]: Done 157 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=8)]: Done 158 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=8)]: Done 159 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=8)]: Done 160 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=8)]: Done 161 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=8)]: Done 162 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=8)]: Done 163 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=8)]: Done 164 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=8)]: Done 166 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=8)]: Done 167 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=8)]: Done 168 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=8)]: Done 169 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=8)]: Done 170 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done 171 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done 172 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done 173 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done 174 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done 175 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done 176 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=8)]: Done 177 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 178 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 179 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 180 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 181 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 182 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 183 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=8)]: Done 185 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 186 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 187 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 188 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 189 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 190 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 191 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 192 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=8)]: Done 193 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=8)]: Done 194 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=8)]: Done 195 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=8)]: Done 196 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=8)]: Done 197 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=8)]: Done 198 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=8)]: Done 199 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=8)]: Done 200 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=8)]: Done 201 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=8)]: Done 202 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=8)]: Done 203 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=8)]: Done 204 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 206 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 207 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 208 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 209 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=8)]: Done 210 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=8)]: Done 211 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=8)]: Done 212 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=8)]: Done 213 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=8)]: Done 214 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=8)]: Done 215 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=8)]: Done 216 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=8)]: Done 217 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=8)]: Done 218 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=8)]: Done 219 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=8)]: Done 220 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=8)]: Done 221 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=8)]: Done 222 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=8)]: Done 223 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=8)]: Done 224 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=8)]: Done 225 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 227 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 228 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 229 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 230 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 231 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=8)]: Done 232 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=8)]: Done 233 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 234 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 235 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 236 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 237 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 238 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 239 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 240 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 241 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=8)]: Done 242 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=8)]: Done 243 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=8)]: Done 244 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=8)]: Done 245 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=8)]: Done 246 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=8)]: Done 247 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=8)]: Done 248 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=8)]: Done 250 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=8)]: Done 251 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=8)]: Done 252 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=8)]: Done 253 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=8)]: Done 254 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=8)]: Done 255 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=8)]: Done 256 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=8)]: Done 257 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=8)]: Done 258 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=8)]: Done 259 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=8)]: Done 260 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=8)]: Done 261 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=8)]: Done 262 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=8)]: Done 263 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=8)]: Done 264 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=8)]: Done 265 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=8)]: Done 266 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=8)]: Done 267 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=8)]: Done 268 tasks      | elapsed: 14.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 269 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=8)]: Done 270 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=8)]: Done 271 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=8)]: Done 273 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=8)]: Done 274 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=8)]: Done 275 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=8)]: Done 276 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=8)]: Done 277 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=8)]: Done 278 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=8)]: Done 279 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=8)]: Done 280 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=8)]: Done 281 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=8)]: Done 282 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=8)]: Done 283 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=8)]: Done 284 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=8)]: Done 285 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=8)]: Done 286 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=8)]: Done 287 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=8)]: Done 288 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=8)]: Done 289 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=8)]: Done 290 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=8)]: Done 291 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=8)]: Done 292 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=8)]: Done 293 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=8)]: Done 294 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=8)]: Done 295 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=8)]: Done 296 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=8)]: Done 298 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=8)]: Done 299 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=8)]: Done 300 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=8)]: Done 301 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=8)]: Done 302 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=8)]: Done 303 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=8)]: Done 304 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=8)]: Done 305 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=8)]: Done 306 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=8)]: Done 307 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=8)]: Done 308 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=8)]: Done 309 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=8)]: Done 310 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=8)]: Done 311 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=8)]: Done 312 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=8)]: Done 313 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=8)]: Done 314 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=8)]: Done 315 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=8)]: Done 316 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=8)]: Done 317 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=8)]: Done 318 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=8)]: Done 319 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=8)]: Done 320 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=8)]: Done 321 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=8)]: Done 323 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=8)]: Done 324 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=8)]: Done 325 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=8)]: Done 326 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=8)]: Done 327 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=8)]: Done 328 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=8)]: Done 329 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=8)]: Done 330 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 331 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 332 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 333 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 334 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 335 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 336 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=8)]: Done 337 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=8)]: Done 338 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=8)]: Done 339 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=8)]: Done 340 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=8)]: Done 341 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=8)]: Done 342 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=8)]: Done 343 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=8)]: Done 344 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=8)]: Done 345 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=8)]: Done 346 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 347 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 348 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 350 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 351 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 352 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=8)]: Done 353 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 354 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 355 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 356 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 357 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 358 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 359 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=8)]: Done 360 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=8)]: Done 361 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=8)]: Done 362 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=8)]: Done 363 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=8)]: Done 364 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=8)]: Done 365 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=8)]: Done 366 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=8)]: Done 367 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=8)]: Done 368 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=8)]: Done 369 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=8)]: Done 370 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 371 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 372 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 373 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 374 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 375 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=8)]: Done 377 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=8)]: Done 378 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=8)]: Done 379 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=8)]: Done 380 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=8)]: Done 381 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=8)]: Done 382 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=8)]: Done 383 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=8)]: Done 384 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=8)]: Done 385 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=8)]: Done 386 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=8)]: Done 387 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 388 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 389 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 390 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 391 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 392 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 393 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=8)]: Done 394 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=8)]: Done 395 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=8)]: Done 396 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=8)]: Done 397 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=8)]: Done 398 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=8)]: Done 399 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=8)]: Done 400 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=8)]: Done 401 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=8)]: Done 402 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=8)]: Done 403 tasks      | elapsed: 21.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 404 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=8)]: Done 406 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=8)]: Done 407 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=8)]: Done 408 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=8)]: Done 409 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=8)]: Done 410 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=8)]: Done 411 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=8)]: Done 412 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=8)]: Done 413 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=8)]: Done 414 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=8)]: Done 415 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=8)]: Done 416 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=8)]: Done 417 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=8)]: Done 418 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=8)]: Done 419 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=8)]: Done 420 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=8)]: Done 421 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=8)]: Done 422 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=8)]: Done 423 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=8)]: Done 424 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=8)]: Done 425 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=8)]: Done 426 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=8)]: Done 427 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=8)]: Done 428 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=8)]: Done 429 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=8)]: Done 430 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=8)]: Done 431 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=8)]: Done 432 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=8)]: Done 433 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=8)]: Done 435 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=8)]: Done 436 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=8)]: Done 437 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=8)]: Done 438 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=8)]: Done 439 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=8)]: Done 440 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=8)]: Done 441 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 442 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 443 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 444 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 445 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 446 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=8)]: Done 447 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=8)]: Done 448 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=8)]: Done 449 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=8)]: Done 450 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=8)]: Done 451 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=8)]: Done 452 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=8)]: Done 453 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=8)]: Done 454 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=8)]: Done 455 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=8)]: Done 456 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=8)]: Done 457 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=8)]: Done 458 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=8)]: Done 459 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=8)]: Done 460 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=8)]: Done 461 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=8)]: Done 462 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=8)]: Done 463 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=8)]: Done 464 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=8)]: Done 466 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=8)]: Done 467 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=8)]: Done 468 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=8)]: Done 469 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=8)]: Done 470 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=8)]: Done 471 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=8)]: Done 472 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=8)]: Done 473 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=8)]: Done 474 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=8)]: Done 475 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=8)]: Done 476 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=8)]: Done 477 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=8)]: Done 478 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=8)]: Done 479 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=8)]: Done 480 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=8)]: Done 481 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 482 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 483 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 484 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 485 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 486 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 487 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 488 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=8)]: Done 489 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 490 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 491 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 492 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 493 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 494 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 495 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=8)]: Done 497 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 498 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 499 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 500 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 501 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 502 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 503 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=8)]: Done 504 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=8)]: Done 505 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 506 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 507 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 508 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 509 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 510 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 511 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=8)]: Done 512 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=8)]: Done 513 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 514 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 515 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 516 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 517 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 518 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 519 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=8)]: Done 520 tasks      | elapsed: 27.2min\n",
      "[Parallel(n_jobs=8)]: Done 521 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 522 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 523 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 524 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 525 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 526 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 527 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 528 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 530 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 531 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 532 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 533 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 534 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done 535 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=8)]: Done 536 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=8)]: Done 537 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 538 tasks      | elapsed: 28.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 539 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 540 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 541 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 542 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 543 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 544 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=8)]: Done 545 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 546 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 547 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 548 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 549 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 550 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 551 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 552 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=8)]: Done 553 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 554 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 555 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 556 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 557 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 558 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 559 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 560 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=8)]: Done 561 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=8)]: Done 563 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=8)]: Done 564 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=8)]: Done 565 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=8)]: Done 566 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=8)]: Done 567 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=8)]: Done 568 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=8)]: Done 569 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=8)]: Done 570 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=8)]: Done 571 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=8)]: Done 572 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=8)]: Done 573 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=8)]: Done 574 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=8)]: Done 575 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=8)]: Done 576 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=8)]: Done 577 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=8)]: Done 578 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 579 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 580 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 581 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 582 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 583 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=8)]: Done 584 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=8)]: Done 585 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=8)]: Done 586 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=8)]: Done 587 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=8)]: Done 588 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=8)]: Done 589 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=8)]: Done 590 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=8)]: Done 591 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=8)]: Done 592 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=8)]: Done 593 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=8)]: Done 594 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=8)]: Done 595 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=8)]: Done 596 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=8)]: Done 598 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=8)]: Done 599 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=8)]: Done 600 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=8)]: Done 601 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=8)]: Done 602 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=8)]: Done 603 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=8)]: Done 604 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=8)]: Done 605 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=8)]: Done 606 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=8)]: Done 607 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=8)]: Done 608 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=8)]: Done 609 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 610 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 611 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 612 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 613 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 614 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 615 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=8)]: Done 616 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=8)]: Done 617 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 618 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 619 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 620 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 621 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 622 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 623 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=8)]: Done 624 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=8)]: Done 625 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 626 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 627 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 628 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 629 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 630 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 631 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=8)]: Done 633 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 634 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 635 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 636 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 637 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 638 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 639 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=8)]: Done 640 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=8)]: Done 641 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=8)]: Done 642 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=8)]: Done 643 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=8)]: Done 644 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=8)]: Done 645 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=8)]: Done 646 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=8)]: Done 647 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=8)]: Done 648 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=8)]: Done 649 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=8)]: Done 650 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=8)]: Done 651 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=8)]: Done 652 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=8)]: Done 653 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=8)]: Done 654 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=8)]: Done 655 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=8)]: Done 656 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=8)]: Done 657 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 658 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 659 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 660 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 661 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 662 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 663 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 664 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=8)]: Done 665 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=8)]: Done 666 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=8)]: Done 667 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=8)]: Done 668 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=8)]: Done 670 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=8)]: Done 671 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=8)]: Done 672 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=8)]: Done 673 tasks      | elapsed: 35.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 674 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=8)]: Done 675 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=8)]: Done 676 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=8)]: Done 677 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=8)]: Done 678 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=8)]: Done 679 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=8)]: Done 680 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=8)]: Done 681 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 682 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 683 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 684 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 685 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 686 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 687 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=8)]: Done 688 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=8)]: Done 689 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=8)]: Done 690 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=8)]: Done 691 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=8)]: Done 692 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=8)]: Done 693 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=8)]: Done 694 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=8)]: Done 695 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=8)]: Done 696 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=8)]: Done 697 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=8)]: Done 698 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=8)]: Done 699 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=8)]: Done 700 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=8)]: Done 701 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=8)]: Done 702 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=8)]: Done 703 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=8)]: Done 704 tasks      | elapsed: 37.1min\n",
      "[Parallel(n_jobs=8)]: Done 705 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=8)]: Done 707 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=8)]: Done 708 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=8)]: Done 709 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=8)]: Done 710 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=8)]: Done 711 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=8)]: Done 712 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=8)]: Done 713 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=8)]: Done 714 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=8)]: Done 715 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=8)]: Done 716 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=8)]: Done 717 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=8)]: Done 718 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=8)]: Done 719 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=8)]: Done 720 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=8)]: Done 721 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=8)]: Done 722 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=8)]: Done 723 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=8)]: Done 724 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=8)]: Done 725 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=8)]: Done 726 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=8)]: Done 727 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=8)]: Done 728 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=8)]: Done 729 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 730 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 731 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 732 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 733 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 734 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 735 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=8)]: Done 736 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=8)]: Done 737 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 738 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 739 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 740 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 741 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 742 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 743 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 744 tasks      | elapsed: 39.1min\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 746 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 747 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 748 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 749 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 750 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 751 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=8)]: Done 752 tasks      | elapsed: 39.5min\n",
      "[Parallel(n_jobs=8)]: Done 753 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=8)]: Done 754 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=8)]: Done 755 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=8)]: Done 756 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=8)]: Done 757 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=8)]: Done 758 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=8)]: Done 759 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=8)]: Done 760 tasks      | elapsed: 39.9min\n",
      "[Parallel(n_jobs=8)]: Done 761 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=8)]: Done 762 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=8)]: Done 763 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=8)]: Done 764 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=8)]: Done 765 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=8)]: Done 766 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=8)]: Done 767 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=8)]: Done 768 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=8)]: Done 769 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=8)]: Done 770 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=8)]: Done 771 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=8)]: Done 772 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=8)]: Done 773 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=8)]: Done 774 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=8)]: Done 775 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=8)]: Done 776 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=8)]: Done 777 tasks      | elapsed: 40.8min\n",
      "[Parallel(n_jobs=8)]: Done 778 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=8)]: Done 779 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=8)]: Done 780 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=8)]: Done 781 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=8)]: Done 782 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=8)]: Done 783 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=8)]: Done 785 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=8)]: Done 786 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=8)]: Done 787 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=8)]: Done 788 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=8)]: Done 789 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=8)]: Done 790 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=8)]: Done 791 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=8)]: Done 792 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=8)]: Done 793 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=8)]: Done 794 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=8)]: Done 795 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 796 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 797 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 798 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 799 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 800 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 801 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=8)]: Done 802 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=8)]: Done 803 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=8)]: Done 804 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=8)]: Done 805 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=8)]: Done 806 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=8)]: Done 807 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=8)]: Done 808 tasks      | elapsed: 42.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 809 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=8)]: Done 810 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 811 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 812 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 813 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 814 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 815 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 816 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=8)]: Done 817 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=8)]: Done 818 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=8)]: Done 819 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=8)]: Done 820 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=8)]: Done 821 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=8)]: Done 822 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=8)]: Done 823 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=8)]: Done 824 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=8)]: Done 826 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=8)]: Done 827 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=8)]: Done 828 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=8)]: Done 829 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=8)]: Done 830 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=8)]: Done 831 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=8)]: Done 832 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=8)]: Done 833 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=8)]: Done 834 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=8)]: Done 835 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=8)]: Done 836 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=8)]: Done 837 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=8)]: Done 838 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=8)]: Done 839 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=8)]: Done 840 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=8)]: Done 841 tasks      | elapsed: 44.2min\n",
      "[Parallel(n_jobs=8)]: Done 842 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=8)]: Done 843 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=8)]: Done 844 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=8)]: Done 845 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=8)]: Done 846 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=8)]: Done 847 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=8)]: Done 848 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=8)]: Done 849 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=8)]: Done 850 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=8)]: Done 851 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=8)]: Done 852 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=8)]: Done 853 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=8)]: Done 854 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=8)]: Done 855 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=8)]: Done 856 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=8)]: Done 857 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=8)]: Done 858 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=8)]: Done 859 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=8)]: Done 860 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=8)]: Done 861 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=8)]: Done 862 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=8)]: Done 863 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=8)]: Done 864 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=8)]: Done 865 tasks      | elapsed: 45.4min\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=8)]: Done 867 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=8)]: Done 868 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=8)]: Done 869 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=8)]: Done 870 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=8)]: Done 871 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=8)]: Done 872 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=8)]: Done 873 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=8)]: Done 874 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 875 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 876 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 877 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 878 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 879 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 880 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=8)]: Done 881 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=8)]: Done 882 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=8)]: Done 883 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=8)]: Done 884 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=8)]: Done 885 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=8)]: Done 886 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=8)]: Done 887 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=8)]: Done 888 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=8)]: Done 889 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=8)]: Done 890 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=8)]: Done 891 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=8)]: Done 892 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=8)]: Done 893 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=8)]: Done 894 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=8)]: Done 895 tasks      | elapsed: 47.6min\n",
      "[Parallel(n_jobs=8)]: Done 896 tasks      | elapsed: 47.6min\n",
      "[Parallel(n_jobs=8)]: Done 897 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=8)]: Done 898 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=8)]: Done 899 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=8)]: Done 900 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=8)]: Done 901 tasks      | elapsed: 48.1min\n",
      "[Parallel(n_jobs=8)]: Done 902 tasks      | elapsed: 48.1min\n",
      "[Parallel(n_jobs=8)]: Done 903 tasks      | elapsed: 48.1min\n",
      "[Parallel(n_jobs=8)]: Done 904 tasks      | elapsed: 48.1min\n",
      "[Parallel(n_jobs=8)]: Done 905 tasks      | elapsed: 48.4min\n",
      "[Parallel(n_jobs=8)]: Done 906 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=8)]: Done 907 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=8)]: Done 908 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=8)]: Done 910 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=8)]: Done 911 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=8)]: Done 912 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=8)]: Done 913 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=8)]: Done 914 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=8)]: Done 915 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=8)]: Done 916 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=8)]: Done 917 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=8)]: Done 918 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=8)]: Done 919 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=8)]: Done 920 tasks      | elapsed: 49.1min\n",
      "[Parallel(n_jobs=8)]: Done 921 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=8)]: Done 922 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=8)]: Done 923 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=8)]: Done 924 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=8)]: Done 925 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=8)]: Done 926 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=8)]: Done 927 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=8)]: Done 928 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=8)]: Done 929 tasks      | elapsed: 49.7min\n",
      "[Parallel(n_jobs=8)]: Done 930 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=8)]: Done 931 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=8)]: Done 932 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=8)]: Done 933 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=8)]: Done 934 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=8)]: Done 935 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=8)]: Done 936 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=8)]: Done 937 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=8)]: Done 938 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=8)]: Done 939 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=8)]: Done 940 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=8)]: Done 941 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=8)]: Done 942 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=8)]: Done 943 tasks      | elapsed: 50.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 944 tasks      | elapsed: 50.3min\n",
      "[Parallel(n_jobs=8)]: Done 945 tasks      | elapsed: 50.5min\n",
      "[Parallel(n_jobs=8)]: Done 960 out of 960 | elapsed: 51.0min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'our',\n",
       "                                                                    'ourselv',\n",
       "                                                                    'you',\n",
       "                                                                    \"you'r\",\n",
       "                                                                    \"you'v\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'your',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselv',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'she',\n",
       "                                                                    'her',\n",
       "                                                                    'her',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'it',\n",
       "                                                                    'it',\n",
       "                                                                    'itself', ...],\n",
       "                                                        tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                                       ('et', ExtraTreesClassifier())]),\n",
       "             n_jobs=8,\n",
       "             param_grid={'cv__max_features': [2500, 5000, 10000],\n",
       "                         'et__max_depth': [10, 50, 100, 500],\n",
       "                         'et__min_samples_leaf': [1, 5, 10, 20],\n",
       "                         'et__min_samples_split': [2, 4, 10, 20]},\n",
       "             verbose=50)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 10000,\n",
       " 'et__max_depth': 100,\n",
       " 'et__min_samples_leaf': 1,\n",
       " 'et__min_samples_split': 10}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6147521675442417"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8731759087291059"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6128133704735376"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still overfit, but seems promising. Let's twiddle some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_et3=Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords, max_features=5000)), \n",
    "                  ('et', ExtraTreesClassifier(max_depth=100))])\n",
    "\n",
    "pipe_et3_params = {\n",
    "                   'et__min_samples_split':[4,10,20,50],\n",
    "                   'et__min_samples_leaf':[5,10,20]\n",
    "                  }\n",
    "gs_et3 = GridSearchCV(pipe_et3, pipe_et3_params, cv=5, n_jobs=7, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=7)]: Done  47 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=7)]: Done  54 out of  60 | elapsed:  2.7min remaining:   18.2s\n",
      "[Parallel(n_jobs=7)]: Done  60 out of  60 | elapsed:  3.0min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_et3.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134914727863776"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716370390023879"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6120175089534421"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5658949243098843"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_et3.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'et__min_samples_leaf': 5, 'et__min_samples_split': 4}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting warmer....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_et4=Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords, max_features=5000)), \n",
    "                  ('et', ExtraTreesClassifier(max_depth=10))])\n",
    "\n",
    "pipe_et4_params = {\n",
    "                   'et__min_samples_split':[20],\n",
    "                   'et__min_samples_leaf':[10],\n",
    "                    'et__n_estimators':[100,1000]\n",
    "                  }\n",
    "gs_et4 = GridSearchCV(pipe_et4, pipe_et4_params, cv=5, n_jobs=7, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   3 out of  10 | elapsed:   18.5s remaining:   43.4s\n",
      "[Parallel(n_jobs=7)]: Done   5 out of  10 | elapsed:   18.7s remaining:   18.7s\n",
      "[Parallel(n_jobs=7)]: Done   7 out of  10 | elapsed:   22.9s remaining:    9.7s\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:   34.9s finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(max_features=5000,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'our',\n",
       "                                                                    'ourselv',\n",
       "                                                                    'you',\n",
       "                                                                    \"you'r\",\n",
       "                                                                    \"you'v\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'your',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselv',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'she',\n",
       "                                                                    'her',\n",
       "                                                                    'her',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'it',\n",
       "                                                                    'it',\n",
       "                                                                    'itself', ...],\n",
       "                                                        tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                                       ('et',\n",
       "                                        ExtraTreesClassifier(max_depth=10))]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'et__min_samples_leaf': [10],\n",
       "                         'et__min_samples_split': [20],\n",
       "                         'et__n_estimators': [100, 1000]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518307243300611"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6010744130521289"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269767441860467"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_et4.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'et__min_samples_leaf': 10,\n",
       " 'et__min_samples_split': 20,\n",
       " 'et__n_estimators': 1000}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_et4.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ada=Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords, max_features=5000)), \n",
    "                  ('ada', AdaBoostClassifier(n_estimators=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5860304138019012"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe_ada,X_train, y_train, cv=5, verbose=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_features=5000,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'our', 'ourselv', 'you',\n",
       "                                             \"you'r\", \"you'v\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'your',\n",
       "                                             'yourself', 'yourselv', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             'she', 'her', 'her', 'herself',\n",
       "                                             'it', 'it', 'it', 'itself', ...],\n",
       "                                 tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                ('ada', AdaBoostClassifier(n_estimators=1000))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.720151233749005"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ada.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5873458018304815"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think this is worth exploring more in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Initial Conclusions\n",
    "\n",
    "From the above tests, I believe the two models worth exploring more are MultinomialNB and BinomialNB. They offered the best scores (although not significantly). Also, they had notably quicker runtime, which makes further exploration easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Refinement\n",
    "\n",
    "Let's play around with a few more parameters, and do some grid searches that might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb2= Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2)), ('mnb', MultinomialNB())])\n",
    "pipe_mnb2_params = {'cv__max_features': [4000, 6000, 8000, 10_000, 12_000],\n",
    "                    'cv__stop_words': [None, custom_stopwords],\n",
    "                    'cv__ngram_range':[(1,1),(1,2),(2,2)],\n",
    "                    'cv__max_df':[1.0, 0.95],\n",
    "                    'cv__min_df':[1, 0.01]}\n",
    "\n",
    "gs_mnb2 = GridSearchCV(pipe_mnb2, pipe_mnb2_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=6)]: Done 600 out of 600 | elapsed: 28.7min finished\n"
     ]
    }
   ],
   "source": [
    "gs_mnb2.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 1.0,\n",
       " 'cv__max_features': 12000,\n",
       " 'cv__min_df': 1,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__stop_words': None}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6237063137011669"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357389227911914"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6237564663748508"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6368350297676205"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_mnb2.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7969821673525377"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb2.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6414930555555556"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb2.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial NB notes before we do an even more in depth search:**\n",
    "- In all tests I've done, including custom_stopwords has outperformed not including it.\n",
    "- Multinomial NB seems to have a preference for large feature sets -- in both cases, our search has selected the largest possible feature set.\n",
    "- min_df and max_df don't seem to be a factor, possibly because we've already yanked stop words.\n",
    "- I have a hunch that n_gram range goes up as features go up, so doing a final search with (1,3) included will be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bnb2= Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, binary=True, stop_words=custom_stopwords)),\n",
    "                     ('bnb', BernoulliNB())])\n",
    "pipe_bnb2_params = {'cv__max_features': [2000, 4000, 6000, 8000, 10_000, 15_000],\n",
    "                    'cv__ngram_range':[(1,1),(1,2),(2,2)]}\n",
    "\n",
    "gs_bnb2 = GridSearchCV(pipe_bnb2, pipe_bnb2_params, cv=5, n_jobs=6, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done  90 out of  90 | elapsed:  4.2min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "gs_bnb2.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190627763041557"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 4000, 'cv__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6840673918811356"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6136092319936332"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5731868131868132"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_bnb2.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7377229080932785"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb2.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293402777777778"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb2.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a search on a multinomial NB over a wide max feature range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb3= Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords)),\n",
    "                     ('mnb', MultinomialNB())])\n",
    "pipe_mnb3_params = {'cv__max_features': range(10000,26000,1000),\n",
    "                    'cv__ngram_range':[(1,1),(1,2),(1,3)],}\n",
    "\n",
    "gs_mnb3 = GridSearchCV(pipe_mnb3, pipe_mnb3_params, cv=5, n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 11.7min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'our',\n",
       "                                                                    'ourselv',\n",
       "                                                                    'you',\n",
       "                                                                    \"you'r\",\n",
       "                                                                    \"you'v\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'your',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselv',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'she',\n",
       "                                                                    'her',\n",
       "                                                                    'her',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'it',\n",
       "                                                                    'it',\n",
       "                                                                    'itself', ...],\n",
       "                                                        tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cv__max_features': range(10000, 26000, 1000),\n",
       "                         'cv__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 15000, 'cv__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6217161979668413"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525205624834174"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6235575009948269"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6361538461538461"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_mnb3.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnb3_preds=gs_mnb3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128943758573388"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423611111111112"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb3.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This increased accuracy by 0.005%, but made the overfitting gap even worse than it already was. Again, it picked the largest n_gram range and largest feature_set. I don't think increasing our feature size is the way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bnb3= Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords, binary=True)),\n",
    "                     ('bnb', BernoulliNB())])\n",
    "pipe_bnb3_params = {'cv__max_features': [2000,4000,6000,8000,10_000,15_000],\n",
    "                    'cv__ngram_range':[(1,1), (1,2)]}\n",
    "\n",
    "gs_bnb3 = GridSearchCV(pipe_bnb3, pipe_bnb3_params, cv=10, n_jobs=6, verbose=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed:  5.8min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(binary=True,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'our',\n",
       "                                                                    'ourselv',\n",
       "                                                                    'you',\n",
       "                                                                    \"you'r\",\n",
       "                                                                    \"you'v\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'your',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselv',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'she',\n",
       "                                                                    'her',\n",
       "                                                                    'her',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'it',\n",
       "                                                                    'it',\n",
       "                                                                    'itself', ...],\n",
       "                                                        tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                                       ('bnb', BernoulliNB())]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'cv__max_features': [2000, 4000, 6000, 8000, 10000,\n",
       "                                              15000],\n",
       "                         'cv__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 15000, 'cv__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246346844698216"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485407269832847"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6195781933943494"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5747330960854093"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=gs_bnb3.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235939643347051"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.score(X_train_long, y_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6319444444444444"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb3.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like all our high feature models are overfitting for marginal increases in accuracy. Let's try to limit these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb4= Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2, stop_words=custom_stopwords)),\n",
    "                     ('mnb', MultinomialNB())])\n",
    "pipe_mnb4_params = {'cv__max_features': [2000,300,400,5000,6000,7000]}\n",
    "\n",
    "gs_mnb4 = GridSearchCV(pipe_mnb4, pipe_mnb4_params, cv=5, n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:   59.2s remaining:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  1.0min remaining:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.2min remaining:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.3min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'our',\n",
       "                                                                    'ourselv',\n",
       "                                                                    'you',\n",
       "                                                                    \"you'r\",\n",
       "                                                                    \"you'v\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'your',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselv',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'she',\n",
       "                                                                    'her',\n",
       "                                                                    'her',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'it',\n",
       "                                                                    'it',\n",
       "                                                                    'itself', ...],\n",
       "                                                        tokenizer=<function snowball_tokens2 at 0x00000246DE381940>)),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cv__max_features': [2000, 300, 400, 5000, 6000,\n",
       "                                              7000]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 7000}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6203236910056262"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115282568320509"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6219657779546359"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bnb4= Pipeline([('cv', CountVectorizer(stop_words=custom_stopwords, binary=True)),\n",
    "                     ('bnb', BernoulliNB())])\n",
    "pipe_bnb4_params = {'cv__max_features': [2000,3000,4000,5000, 6000, 7000],\n",
    "                   'cv__tokenizer': [snowball_tokens, snowball_tokens2]}\n",
    "\n",
    "gs_bnb4 = GridSearchCV(pipe_bnb4, pipe_bnb4_params, cv=5, n_jobs=6, verbose=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done  56 out of  60 | elapsed:  2.7min remaining:   11.5s\n",
      "[Parallel(n_jobs=6)]: Done  60 out of  60 | elapsed:  2.7min finished\n",
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(binary=True,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'our',\n",
       "                                                                    'ourselv',\n",
       "                                                                    'you',\n",
       "                                                                    \"you'r\",\n",
       "                                                                    \"you'v\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'your',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselv',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'she',\n",
       "                                                                    'her',\n",
       "                                                                    'her',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'it',\n",
       "                                                                    'it',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('bnb', BernoulliNB())]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'cv__max_features': [2000, 3000, 4000, 5000, 6000,\n",
       "                                              7000],\n",
       "                         'cv__tokenizer': [<function snowball_tokens at 0x00000246DE381AF0>,\n",
       "                                           <function snowball_tokens2 at 0x00000246DE381940>]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_features': 4000,\n",
       " 'cv__tokenizer': <function __main__.snowball_tokens2(text)>}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190627763041557"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6840673918811356"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6136092319936332"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bnb4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes from running a bunch of different gridsearches:\n",
    "\n",
    "Increasing features and n-grams slightly increases accuracy, but at the expense of serious overfitting. Most of our \"good\" models are in the range of 61 +-1% accuracy for the test set.\n",
    "\n",
    "Using difference from training set accuracy as an overfitting metric, we have gaps of 7% in our best Bernoulli models. We can get an extra 0.5% in accuracy in a Multinomial NB model, but at the cost of increasing the training/test gap to 16%.\n",
    "\n",
    "Increasing cross validation from 5 to 10 fold slightly increased model performance, but changed parameters towards overfitting.\n",
    "\n",
    "I think the Bernoulli Naive Bayesian model with 4000 max features and with snowball_tokens2 is the winner.\n",
    "\n",
    "After this mess of trial and error, let's fully analyze our model in a new workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df.to_csv('..\\data\\canada_subreddit_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

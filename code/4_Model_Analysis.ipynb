{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow=SnowballStemmer(\"english\")\n",
    "def snowball_tokens2(text):\n",
    "    text_processed = re.sub(r'[^A-Za-z]', ' ', text).split()\n",
    "    tokens = [snow.stem(word) for word in text_processed]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df = pd.read_csv('..\\data\\canada_subreddit_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords= stopwords.words('english')\n",
    "custom_stopwords.extend(['people', 'like', 'canada'])\n",
    "custom_stopwords = [snow.stem(word) for word in custom_stopwords]\n",
    "#I'm cheating and adding a few more stopwords here that I identfied as highly shared between both subreddits\n",
    "#that I didn't identify until after doing some more analysis on top tokens\n",
    "\n",
    "extra_stopwords=['get', 'would', 'gt', 'one', 'go', 'make', \n",
    "                 'actual', 'also', 'back', 'us', 'use', 'could', 'say', 'said', 'see', 'back', 'come',\n",
    "                'canadian', 'look']\n",
    "\n",
    "custom_stopwords.extend(extra_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=canada_df['body_processed']\n",
    "y=canada_df['subreddit_bin']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_final= Pipeline([('cv', CountVectorizer(tokenizer=snowball_tokens2,\n",
    "                                            max_features=4000,\n",
    "                                            stop_words=custom_stopwords,\n",
    "                                            binary=True)), \n",
    "                     ('bnb', BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "bnb_final.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle export\n",
    "\n",
    "pickle.dump(bnb_final, open(\"final_model.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that by grid search, we identified a final model to be a Binomial Naive Bayes classifier, with the binary  CountVectorizer taking 4000 features, stopwords removed and a stemming tokenizer. Let's also recall that a positive result corresponds to a comment being classified in r\\OnGuardForThee, and a negative result corresponds to being classified in r\\Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6841337224728045"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_final.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6146040588937525"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_final.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also recall that we like analyzing longer comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_long = X_test[X_test.str.split().str.len() > 50]\n",
    "y_test_long = y_test[X_test.str.split().str.len() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6319444444444444"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_final.score(X_test_long, y_test_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's keep our baseline here for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.503979\n",
       "0    0.496021\n",
       "Name: subreddit_bin, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2533\n",
       "0    2493\n",
       "Name: subreddit_bin, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5026,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a confusion matrix and take a look at our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=bnb_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cm=confusion_matrix(y_test, preds)\n",
    "tn, fp, fn, tp = final_cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1782,  711],\n",
       "       [1226, 1307]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3008"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn+fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp + fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite that the data is split about 50/50 between OGFT and Canada comments, it's guessing about 60% of the comments are from r/Canada, and 40% of the comments are from OGFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6146040588937525"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall/Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5159889459139361"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're correctly identifying 51% the OGFT posts. This isn't great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7148014440433214"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn/(tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity is doing better: we're hitting 71% of the Canada posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6476709613478692"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is 64.8% precise at identifying r/OnGuardForThee posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924202127659575"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tn)/(tn+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's 59% precise at identifying r/Canada posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5743792573060865"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These aren't great results, but they are consistently above the baseline. They also confirm some of the things that we observed in the data exploration. Overall, it seems that the model is much better at identifying r/Canada posts than r/OnGuardForThee\n",
    " \n",
    "Though the results aren't necessarily great, given the wide overlap in subject matter and consistently above baseline performance, I think that our model is grabbing onto something interesting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics for long comments\n",
    "\n",
    "Is there a length threshold for comments that gives us better accuracy? We previously showed that the model is more accurate on comments of >50 words. Let's see if we can identify a word length cutoff that maximizes accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_long = X_test[X_test.str.split().str.len() > 50]\n",
    "y_test_long = y_test[X_test.str.split().str.len() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "Best accuracy of 0.6389085754783841 is achieved predicting comments of length 20 words or greater\n"
     ]
    }
   ],
   "source": [
    "acc_score=0\n",
    "threshold=0\n",
    "for i in range(0,250):\n",
    "    print(i)\n",
    "    X_test_l=X_test[X_test.str.split().str.len() > i]\n",
    "    y_test_l = y_test[X_test.str.split().str.len() > i]\n",
    "    i_acc=bnb_final.score(X_test_l, y_test_l)\n",
    "    if i_acc > acc_score:\n",
    "        acc_score=i_acc\n",
    "        threshold = i\n",
    "\n",
    "print(f\"Best accuracy of {acc_score} is achieved predicting comments of length {threshold} words or greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get a an accuracy improvement of up to 0.639% (from 0.614) if we restrict to comments that have more than 20 words. Let's rerun our classification metrics for just this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_long = X_test[X_test.str.split().str.len() > 20]\n",
    "y_test_long = y_test[X_test.str.split().str.len() > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.515946\n",
       "0    0.484054\n",
       "Name: subreddit_bin, dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_long.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1456\n",
       "0    1366\n",
       "Name: subreddit_bin, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_long.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a sample test set with near 3000 values, and close to 50% balance between classes. So our stratification isn't too skewed by the wordcount restriction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_long=bnb_final.predict(X_test_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_long=confusion_matrix(y_test_long, preds_long)\n",
    "tn_l, fp_l, fn_l, tp_l = cm_long.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[863, 503],\n",
       "       [516, 940]], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_l + fn_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_l + fp_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for this test set are much more balanced -- it's guessing categories much closer to their actual proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389085754783841"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_long, preds_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6456043956043956"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test_long, preds_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6317715959004392"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_l/(tn_l + fp_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6514206514206514"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test_long, preds_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is 65% precise at identifying long comments to be in r/OnGuardForThee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6258158085569253"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_l/(tn_l+fn_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's 63% precise at identifying r/Canada posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6484994825802001"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_long, preds_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that restricting our test set to comments of greater than 20 words significantly improves performance. All metrics except specificity show improvement, some significantly. This seems to imply that the model was disproportionately guessing comments of 20 words or under to be in r/Canada, increasing specificity at the expense of everything else.\n",
    "\n",
    "Though not included here, training our model (in it's current form) on exclusively long comments actually slightly reduces performance. It seems like the model is \"learning\" something useful from smaller comments that's useful for predicting larger ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Analysis of Short Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_short = X_test[X_test.str.split().str.len() <= 20]\n",
    "y_test_short = y_test[X_test.str.split().str.len() <= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204,)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.511343\n",
       "1    0.488657\n",
       "Name: subreddit_bin, dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_short.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1127\n",
       "1    1077\n",
       "Name: subreddit_bin, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_short.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_short=bnb_final.predict(X_test_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_short=confusion_matrix(y_test_short, preds_short)\n",
    "tn_s, fp_s, fn_s, tp_s = cm_short.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[919, 208],\n",
       "       [710, 367]], dtype=int64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_s + fp_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_s + fn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, the model is significantly skewed towards guessing that short comments are from r/Canada, despite them being near balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5834845735027223"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_short, preds_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34076137418755803"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test_short, preds_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8154392191659272"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_s/(tn_s+fp_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6382608695652174"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test_short, preds_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canada precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5641497851442603"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_s/(tn_s+fn_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44430992736077485"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_short, preds_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis/Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm particularly interested in comments that our model assigned high probabilities to. Let's investigate some such comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probs=bnb_final.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5026, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89153374, 0.77489858, 0.69960435, ..., 0.35682451, 0.79064755,\n",
       "       0.73541651])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_probs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_probs=pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_probs['canada_prob']=predict_probs[:,0]\n",
    "comment_probs['ogft_prob']=predict_probs[:,1]\n",
    "comment_probs['subreddit']=y_test.map({0:'r/canada', 1:'r/onguardforthee'})\n",
    "comment_probs['y_pred']=preds\n",
    "comment_probs['y_true']=y_test\n",
    "comment_probs['correct']= comment_probs['y_pred']==comment_probs['y_true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_processed</th>\n",
       "      <th>canada_prob</th>\n",
       "      <th>ogft_prob</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Hah, so damn sensitive. Where have I insulted ...</td>\n",
       "      <td>0.891534</td>\n",
       "      <td>0.108466</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>I'm glad she is at least free of that pain and...</td>\n",
       "      <td>0.774899</td>\n",
       "      <td>0.225101</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>I got an idea, lets ban murder all together. T...</td>\n",
       "      <td>0.699604</td>\n",
       "      <td>0.300396</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>The flu causes all those things too. So does e...</td>\n",
       "      <td>0.981876</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>yeah, you're right. Canadians who were born he...</td>\n",
       "      <td>0.393335</td>\n",
       "      <td>0.606665</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17690</th>\n",
       "      <td>I never want to deal with US style Healthcare,...</td>\n",
       "      <td>0.245613</td>\n",
       "      <td>0.754387</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>Sooooo CBC?</td>\n",
       "      <td>0.710833</td>\n",
       "      <td>0.289167</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>Source: http://projects.thestar.com/canadas-co...</td>\n",
       "      <td>0.356825</td>\n",
       "      <td>0.643175</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11159</th>\n",
       "      <td>It seems like a radical idea to decriminalize ...</td>\n",
       "      <td>0.790648</td>\n",
       "      <td>0.209352</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>Exactly, you lease it as a business expense fo...</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5026 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body_processed  canada_prob  \\\n",
       "2494   Hah, so damn sensitive. Where have I insulted ...     0.891534   \n",
       "4753   I'm glad she is at least free of that pain and...     0.774899   \n",
       "12281  I got an idea, lets ban murder all together. T...     0.699604   \n",
       "10206  The flu causes all those things too. So does e...     0.981876   \n",
       "5494   yeah, you're right. Canadians who were born he...     0.393335   \n",
       "...                                                  ...          ...   \n",
       "17690  I never want to deal with US style Healthcare,...     0.245613   \n",
       "5629                                         Sooooo CBC?     0.710833   \n",
       "6099   Source: http://projects.thestar.com/canadas-co...     0.356825   \n",
       "11159  It seems like a radical idea to decriminalize ...     0.790648   \n",
       "5072   Exactly, you lease it as a business expense fo...     0.735417   \n",
       "\n",
       "       ogft_prob         subreddit  y_pred  y_true  correct  \n",
       "2494    0.108466  r/onguardforthee       0       1    False  \n",
       "4753    0.225101  r/onguardforthee       0       1    False  \n",
       "12281   0.300396          r/canada       0       0     True  \n",
       "10206   0.018124          r/canada       0       0     True  \n",
       "5494    0.606665  r/onguardforthee       1       1     True  \n",
       "...          ...               ...     ...     ...      ...  \n",
       "17690   0.754387          r/canada       1       0    False  \n",
       "5629    0.289167  r/onguardforthee       0       1    False  \n",
       "6099    0.643175  r/onguardforthee       1       1     True  \n",
       "11159   0.209352          r/canada       0       0     True  \n",
       "5072    0.264583  r/onguardforthee       0       1    False  \n",
       "\n",
       "[5026 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at comments that the model was very certain about. Let's see what was above a 95% probability threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_processed</th>\n",
       "      <th>canada_prob</th>\n",
       "      <th>ogft_prob</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>I absolutely agree with you on all points. Tru...</td>\n",
       "      <td>7.777650e-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>&amp;gt; Maybe it's because everyone is cooped up ...</td>\n",
       "      <td>5.241745e-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>&amp;gt; The mayor of Summerland, B.C., is declini...</td>\n",
       "      <td>4.363294e-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>You are right about the attitude towards addic...</td>\n",
       "      <td>3.440726e-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>I was one of the founding mods of /canada- I d...</td>\n",
       "      <td>1.339018e-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>\" Dude wore MAGA hats and worshipped Trump.  \"...</td>\n",
       "      <td>5.718436e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>yeah i know, theyve done that to me countless ...</td>\n",
       "      <td>1.718890e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15081</th>\n",
       "      <td>&amp;gt;your conflating a deference in politics wi...</td>\n",
       "      <td>4.287370e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>If the UCP/right wing/alt-right think we're go...</td>\n",
       "      <td>9.248932e-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>The only way to effectively stop divisive dirt...</td>\n",
       "      <td>3.152664e-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body_processed   canada_prob  \\\n",
       "8775   I absolutely agree with you on all points. Tru...  7.777650e-09   \n",
       "1946   &gt; Maybe it's because everyone is cooped up ...  5.241745e-09   \n",
       "10980  &gt; The mayor of Summerland, B.C., is declini...  4.363294e-09   \n",
       "5536   You are right about the attitude towards addic...  3.440726e-09   \n",
       "7273   I was one of the founding mods of /canada- I d...  1.339018e-09   \n",
       "7930   \" Dude wore MAGA hats and worshipped Trump.  \"...  5.718436e-11   \n",
       "1638   yeah i know, theyve done that to me countless ...  1.718890e-11   \n",
       "15081  &gt;your conflating a deference in politics wi...  4.287370e-13   \n",
       "7466   If the UCP/right wing/alt-right think we're go...  9.248932e-15   \n",
       "4926   The only way to effectively stop divisive dirt...  3.152664e-15   \n",
       "\n",
       "       ogft_prob         subreddit  y_pred  y_true  correct  \n",
       "8775         1.0  r/onguardforthee       1       1     True  \n",
       "1946         1.0  r/onguardforthee       1       1     True  \n",
       "10980        1.0          r/canada       1       0    False  \n",
       "5536         1.0  r/onguardforthee       1       1     True  \n",
       "7273         1.0  r/onguardforthee       1       1     True  \n",
       "7930         1.0  r/onguardforthee       1       1     True  \n",
       "1638         1.0  r/onguardforthee       1       1     True  \n",
       "15081        1.0          r/canada       1       0    False  \n",
       "7466         1.0  r/onguardforthee       1       1     True  \n",
       "4926         1.0  r/onguardforthee       1       1     True  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['ogft_prob'] >=0.95].sort_values('ogft_prob').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.745098\n",
       "False    0.254902\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['ogft_prob'] >=0.95]['correct'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_processed</th>\n",
       "      <th>canada_prob</th>\n",
       "      <th>ogft_prob</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>The flu causes all those things too. So does e...</td>\n",
       "      <td>0.981876</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19690</th>\n",
       "      <td>Unless I'm getting table service or I'm waited...</td>\n",
       "      <td>0.978532</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16462</th>\n",
       "      <td>This is what happens when you have wolves in c...</td>\n",
       "      <td>0.980541</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20023</th>\n",
       "      <td>A friend of mine just told me that if you show...</td>\n",
       "      <td>0.985260</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>&amp;gt;The CRTC has sided with Canada’s largest w...</td>\n",
       "      <td>0.991513</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17433</th>\n",
       "      <td>So tangentially, is there data on people who o...</td>\n",
       "      <td>0.958211</td>\n",
       "      <td>0.041789</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>let them use their cell phone profits to pay f...</td>\n",
       "      <td>0.963772</td>\n",
       "      <td>0.036228</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>&amp;gt;Diversify Yo Bonds\\n\\n- Wu-Tang Financial</td>\n",
       "      <td>0.958520</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>I totally agree with you that we’ve become nor...</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17506</th>\n",
       "      <td>Holy MadLad! Doing this outside the HoC means ...</td>\n",
       "      <td>0.958315</td>\n",
       "      <td>0.041685</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body_processed  canada_prob  \\\n",
       "10206  The flu causes all those things too. So does e...     0.981876   \n",
       "19690  Unless I'm getting table service or I'm waited...     0.978532   \n",
       "16462  This is what happens when you have wolves in c...     0.980541   \n",
       "20023  A friend of mine just told me that if you show...     0.985260   \n",
       "17290  &gt;The CRTC has sided with Canada’s largest w...     0.991513   \n",
       "...                                                  ...          ...   \n",
       "17433  So tangentially, is there data on people who o...     0.958211   \n",
       "16626  let them use their cell phone profits to pay f...     0.963772   \n",
       "1659       &gt;Diversify Yo Bonds\\n\\n- Wu-Tang Financial     0.958520   \n",
       "15006  I totally agree with you that we’ve become nor...     0.999865   \n",
       "17506  Holy MadLad! Doing this outside the HoC means ...     0.958315   \n",
       "\n",
       "       ogft_prob         subreddit  y_pred  y_true  correct  \n",
       "10206   0.018124          r/canada       0       0     True  \n",
       "19690   0.021468          r/canada       0       0     True  \n",
       "16462   0.019459          r/canada       0       0     True  \n",
       "20023   0.014740          r/canada       0       0     True  \n",
       "17290   0.008487          r/canada       0       0     True  \n",
       "...          ...               ...     ...     ...      ...  \n",
       "17433   0.041789          r/canada       0       0     True  \n",
       "16626   0.036228          r/canada       0       0     True  \n",
       "1659    0.041480  r/onguardforthee       0       1    False  \n",
       "15006   0.000135          r/canada       0       0     True  \n",
       "17506   0.041685          r/canada       0       0     True  \n",
       "\n",
       "[339 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['canada_prob'] >=0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.731563\n",
       "False    0.268437\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['canada_prob'] >=0.95]['correct'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 5030 test values, about 850 were classified as having a 95% probability of belonging to a given category.\n",
    "- For r/onguardforthee, 74% of these predictions were correct.\n",
    "- For r/canada, 73% of these predictions were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's crank the threshold up even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_processed</th>\n",
       "      <th>canada_prob</th>\n",
       "      <th>ogft_prob</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>\"Fiscally Conservative\" is a myth and a fairly...</td>\n",
       "      <td>6.117520e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>The only way to effectively stop divisive dirt...</td>\n",
       "      <td>3.152664e-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15081</th>\n",
       "      <td>&amp;gt;your conflating a deference in politics wi...</td>\n",
       "      <td>4.287370e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>Are the pollsters not calling them? I'm so sic...</td>\n",
       "      <td>7.321075e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>And see this is where we differ ; you are scar...</td>\n",
       "      <td>1.168728e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>No kidding. r/Canada is still going strong, to...</td>\n",
       "      <td>3.349545e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>Antifa is the propaganda boogeyman of the alt ...</td>\n",
       "      <td>5.771782e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>I was one of the founding mods of /canada- I d...</td>\n",
       "      <td>1.339018e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>I don't know what it's like to raise a child, ...</td>\n",
       "      <td>4.249685e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>&amp;gt;Premier Ford has a net favourability ratin...</td>\n",
       "      <td>1.448484e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9283</th>\n",
       "      <td>As an Albertan who has volunteered for the Alb...</td>\n",
       "      <td>8.509606e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742</th>\n",
       "      <td>Watched this video yesterday and thought it wa...</td>\n",
       "      <td>1.346310e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>I absolutely agree with you on all points. Tru...</td>\n",
       "      <td>7.777650e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>This is one of the most downvoted communities ...</td>\n",
       "      <td>3.135151e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>&amp;gt; Maybe it's because everyone is cooped up ...</td>\n",
       "      <td>5.241745e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>If I can explain myself: this is the only subr...</td>\n",
       "      <td>4.364840e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>yeah i know, theyve done that to me countless ...</td>\n",
       "      <td>1.718890e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13057</th>\n",
       "      <td>I just want to clarify that Liberals no longer...</td>\n",
       "      <td>8.602960e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>What a fucking disgrace. Ford is just going to...</td>\n",
       "      <td>7.361917e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>&amp;gt; Why are we constantly being told that we ...</td>\n",
       "      <td>7.038222e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>If the UCP/right wing/alt-right think we're go...</td>\n",
       "      <td>9.248932e-15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>This is a very unpopular opinion,  especially ...</td>\n",
       "      <td>1.935284e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>&amp;gt; There is a difference between sex and gen...</td>\n",
       "      <td>1.844250e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9420</th>\n",
       "      <td>&amp;gt; McInnes, a Vice co-founder who left the m...</td>\n",
       "      <td>1.366492e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>Citations Needed is beast.  Everyone should jo...</td>\n",
       "      <td>8.909457e-07</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>You are right about the attitude towards addic...</td>\n",
       "      <td>3.440726e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>Is it silly? Yes. Petty, sure, but I and the l...</td>\n",
       "      <td>4.413697e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>The Youtube comments makes a good point: the p...</td>\n",
       "      <td>1.229601e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9696</th>\n",
       "      <td>You don't have to dig too deeply to realize th...</td>\n",
       "      <td>2.360783e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>\" Dude wore MAGA hats and worshipped Trump.  \"...</td>\n",
       "      <td>5.718436e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>&amp;gt; The mayor of Summerland, B.C., is declini...</td>\n",
       "      <td>4.363294e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body_processed   canada_prob  \\\n",
       "437    \"Fiscally Conservative\" is a myth and a fairly...  6.117520e-07   \n",
       "4926   The only way to effectively stop divisive dirt...  3.152664e-15   \n",
       "15081  &gt;your conflating a deference in politics wi...  4.287370e-13   \n",
       "5189   Are the pollsters not calling them? I'm so sic...  7.321075e-07   \n",
       "8281   And see this is where we differ ; you are scar...  1.168728e-07   \n",
       "4659   No kidding. r/Canada is still going strong, to...  3.349545e-08   \n",
       "9115   Antifa is the propaganda boogeyman of the alt ...  5.771782e-07   \n",
       "7273   I was one of the founding mods of /canada- I d...  1.339018e-09   \n",
       "7184   I don't know what it's like to raise a child, ...  4.249685e-08   \n",
       "6875   &gt;Premier Ford has a net favourability ratin...  1.448484e-07   \n",
       "9283   As an Albertan who has volunteered for the Alb...  8.509606e-07   \n",
       "7742   Watched this video yesterday and thought it wa...  1.346310e-07   \n",
       "8775   I absolutely agree with you on all points. Tru...  7.777650e-09   \n",
       "6052   This is one of the most downvoted communities ...  3.135151e-08   \n",
       "1946   &gt; Maybe it's because everyone is cooped up ...  5.241745e-09   \n",
       "1414   If I can explain myself: this is the only subr...  4.364840e-07   \n",
       "1638   yeah i know, theyve done that to me countless ...  1.718890e-11   \n",
       "13057  I just want to clarify that Liberals no longer...  8.602960e-07   \n",
       "9462   What a fucking disgrace. Ford is just going to...  7.361917e-07   \n",
       "6809   &gt; Why are we constantly being told that we ...  7.038222e-07   \n",
       "7466   If the UCP/right wing/alt-right think we're go...  9.248932e-15   \n",
       "7231   This is a very unpopular opinion,  especially ...  1.935284e-07   \n",
       "5853   &gt; There is a difference between sex and gen...  1.844250e-08   \n",
       "9420   &gt; McInnes, a Vice co-founder who left the m...  1.366492e-07   \n",
       "4202   Citations Needed is beast.  Everyone should jo...  8.909457e-07   \n",
       "5536   You are right about the attitude towards addic...  3.440726e-09   \n",
       "8300   Is it silly? Yes. Petty, sure, but I and the l...  4.413697e-08   \n",
       "8925   The Youtube comments makes a good point: the p...  1.229601e-08   \n",
       "9696   You don't have to dig too deeply to realize th...  2.360783e-07   \n",
       "7930   \" Dude wore MAGA hats and worshipped Trump.  \"...  5.718436e-11   \n",
       "10980  &gt; The mayor of Summerland, B.C., is declini...  4.363294e-09   \n",
       "\n",
       "       ogft_prob         subreddit  y_pred  y_true  correct  \n",
       "437     0.999999  r/onguardforthee       1       1     True  \n",
       "4926    1.000000  r/onguardforthee       1       1     True  \n",
       "15081   1.000000          r/canada       1       0    False  \n",
       "5189    0.999999  r/onguardforthee       1       1     True  \n",
       "8281    1.000000  r/onguardforthee       1       1     True  \n",
       "4659    1.000000  r/onguardforthee       1       1     True  \n",
       "9115    0.999999  r/onguardforthee       1       1     True  \n",
       "7273    1.000000  r/onguardforthee       1       1     True  \n",
       "7184    1.000000  r/onguardforthee       1       1     True  \n",
       "6875    1.000000  r/onguardforthee       1       1     True  \n",
       "9283    0.999999  r/onguardforthee       1       1     True  \n",
       "7742    1.000000  r/onguardforthee       1       1     True  \n",
       "8775    1.000000  r/onguardforthee       1       1     True  \n",
       "6052    1.000000  r/onguardforthee       1       1     True  \n",
       "1946    1.000000  r/onguardforthee       1       1     True  \n",
       "1414    1.000000  r/onguardforthee       1       1     True  \n",
       "1638    1.000000  r/onguardforthee       1       1     True  \n",
       "13057   0.999999          r/canada       1       0    False  \n",
       "9462    0.999999  r/onguardforthee       1       1     True  \n",
       "6809    0.999999  r/onguardforthee       1       1     True  \n",
       "7466    1.000000  r/onguardforthee       1       1     True  \n",
       "7231    1.000000  r/onguardforthee       1       1     True  \n",
       "5853    1.000000  r/onguardforthee       1       1     True  \n",
       "9420    1.000000  r/onguardforthee       1       1     True  \n",
       "4202    0.999999  r/onguardforthee       1       1     True  \n",
       "5536    1.000000  r/onguardforthee       1       1     True  \n",
       "8300    1.000000  r/onguardforthee       1       1     True  \n",
       "8925    1.000000  r/onguardforthee       1       1     True  \n",
       "9696    1.000000  r/onguardforthee       1       1     True  \n",
       "7930    1.000000  r/onguardforthee       1       1     True  \n",
       "10980   1.000000          r/canada       1       0    False  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['ogft_prob'] >=0.999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 7)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['ogft_prob'] >=0.999999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.903226\n",
       "False    0.096774\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['ogft_prob'] >=0.999999]['correct'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_processed</th>\n",
       "      <th>canada_prob</th>\n",
       "      <th>ogft_prob</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19058</th>\n",
       "      <td>Serious answer? \\n\\n1. Huawei is the only vend...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.785689e-08</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body_processed  canada_prob  \\\n",
       "19058  Serious answer? \\n\\n1. Huawei is the only vend...          1.0   \n",
       "\n",
       "          ogft_prob subreddit  y_pred  y_true  correct  \n",
       "19058  4.785689e-08  r/canada       0       0     True  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['canada_prob'] >=0.999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['canada_prob'] >=0.999999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    1.0\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_probs[comment_probs['canada_prob'] >=0.999999]['correct'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22+1= comments were predicted as having almost near certainty to belong in a given category (>0.999999 chance) - 22 in OnGuardForThee, 1 in Cananada. This is interesting, given that the model is much better at predicting if a post is in r/Canada.\n",
    "\n",
    "## Representative comments\n",
    "\n",
    "Let's take a look at the high certainty comments that were predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_can=comment_probs[(comment_probs['canada_prob'] >=0.999999 ) &(comment_probs['correct']==1)]['body_processed']\n",
    "top_ogft=comment_probs[(comment_probs['ogft_prob'] >=0.999999) & (comment_probs['correct']==1)]['body_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_can.str.split().str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193.17857142857142"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ogft.str.split().str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_can.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ogft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our average wordcount was around 44 words, while these comments have an average wordcount of over 250. So it seems that longer comments have a higher chance of being properly classified, or at least our model weights wordcount when assigning a category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at comments that the model foud extremely difficult to predict, where the probability of them being in a given subreddit was assigned to be $50 \\pm 0.001\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_comments =comment_probs[(comment_probs['canada_prob'] >=0.499)& (comment_probs['ogft_prob'] >=0.499)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertain_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.11111111111111"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertain_comments['body_processed'].str.split().str.len().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have nine such comments. On average, they each contain 27 words. Seven of these were actually identified correctly, but that's mostly luck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest Probability r/OnGuardForThee Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Fiscally Conservative\" is a myth and a fairly new concept perpetuated by the right in an attempt to garner socially liberal votes and make people think they're doing something positive.\n",
      "\n",
      "A government either knows how to handle money responsibly, or they don't. Funding social programs is a fiscally responsible initiative. It brings economic prosperity by boosting up marginalized populations so that they're contributing to a local and national economy. It's been proven by economic theory countless times.\n",
      "\n",
      "Tax breaks for no reason to profitable corporations who hoard money in tax havens is not fiscally responsible. It's corporate welfare. Neither is cutting funding to education and other necessary items for a society to function. Austerity measures are a proven failure time and time again, but historically, Conservatives view it as an economic plan to recovery in recession (or any time for that matter).\n",
      "\n",
      "\"Fiscally Conservative\" is almost becoming a slur to describe the \"I got mine, now you can get fucked\" mentality of far-right Conservative voters. Trust me. I live in Alberta where this thought process reigns supreme.\n",
      "\n",
      "Also, unrelated to your comment, I must say...Ed the Sock is a Canadian nuisance. I wish he would get lost in a dryer somewhere.\n",
      " ---------------------------\n",
      "The only way to effectively stop divisive dirty politics like this where they seek increase voter apathy, disenfranchisement, and straight up use voter suppression through misinformation and gerrymandering is to stop using a voting system that encourages it.\n",
      "\n",
      "FPTP encourages these toxic anti-democratic political manipulations through a simple mathematical reality of the system of First Past The Post: It is designed to give minority voting blocks in a riding the choice of who represents them, leaving the other voting blocks that voted against that result out in the disenfranchised cold to be called split, protest, and wasted votes.\n",
      "\n",
      "Here’s the cold hard math of FPTP: Minimum Thresholds To Win (MT).\n",
      "\n",
      "A) 2 candidates on a riding’s ballot. MT = 50.1% of the votes. This the only time a majority of the votes is the minimum to win.\n",
      "\n",
      "B) 3 candidates on a riding’s ballot. MT = 33.4% of the votes. It doesn’t take much to have a majority upwards of 66.6% not be a part of who isn’t voted in.\n",
      "\n",
      "C) 4 candidates on a riding’s ballot. MT = 25.1% of the votes. Up to 74.9% of us potentially have our political voice ignored.\n",
      "\n",
      "D) 5 candidates on a riding’s ballot. MT = 20.1% of the votes. Up to 79.9% of us considered protest votes of the winner.\n",
      "\n",
      "E) 6 candidates on a riding’s ballot. MT = 16.7% of the votes. Up to 83.3% of us could have our votes called split.\n",
      "\n",
      "F) 7 candidates on a riding’s ballot. MT = 14.4% of the votes. Up to 85.6% of us told we wasted our votes not picking second place.\n",
      "\n",
      "G) Etc...\n",
      "\n",
      "Canada has a lot of political candidates on our ballots, we currently have what I would consider 5 major parties (they’ve successfully convinced a riding to elect their candidate to a MP seat under FPTP) running candidates in as many ridings as they can, not even accounting for the independents and smaller party’s candidates each taking a piece of the pie of votes in their riding’s ballots.\n",
      "\n",
      "This is why political parties in Canada realize they don’t need to appeal to as many of us as possible, they only need to have a loyal and dedicated voting block that meets the MT or better in your riding, everything after that is just convincing the others to not bother showing up. The lower the voter turnout is, the better loyalists do, so how do you get your opponents to not bother showing up? Apathy - convince your opponent’s supporters that either:\n",
      "\n",
      "A) their choice doesn’t matter or worse gives them the opposite result, like Liberal supporters like to tell NDP supporters. Or...\n",
      "\n",
      "B) turn up the toxic rhetoric like the Conservative supporters do. Nothing is too low to sink to, especially projecting that all politicians are just as bad as each other. Or...\n",
      "\n",
      "C) Release polls claiming your side already has the biggest voting block and if you want to conform, you better pay attention to which way the wind is blowing. Chances are pretty good under FPTP as demonstrated above that you’re in the majority that doesn’t win the seat, so if you don’t want to go through the stress of being an outcast...\n",
      "\n",
      "But there is hope, you’re not alone in realizing that FPTP is being gamed and incentivizing bad politics to win the seat. Canadians know this isn’t fair and over 130 000 of us courageously signed a e-petition on our official government site, calling for electoral reform to stop using FPTP.  We know we need a voting system that does more to bring us together rather than divide us into Us vs Them camps. And currently one party is asking us permission to enact real change to our voting system - the NDP has Mixed Member Proportional (MMP) with a sunset clause to have a referendum after trying it, so we all know exactly in real terms we experienced the exact details of, so we can all be informed voters when we pick to keep MMP or go back to the FPTP discussed above.\n",
      "\n",
      "A courageous vote for the NDP is a vote to move away from American style of political discourse and voter suppression that comes from using FPTP in Canada.\n",
      "\n",
      "Edit: Oops, typed up the wrong number, sorry.\n",
      " ---------------------------\n",
      "Are the pollsters not calling them? I'm so sick of polls and bubble coverage moulding public opinion.\n",
      "\n",
      "He fucked up. He acknowledged as such and apologized. He even broke down and cried. Judge him on his policy record since, FFS. The man is NOT RACIST.\n",
      "\n",
      "I really fail to see how people supporting the party of unapologetic racists are doing their part to show that racism is bad. For the love of god, he personally welcomed refugee children with coats and blankets at Pearson Airport. He *saved lives*. He's been viciously attacked for it by rancid bigots and Islamophobes accusing him of pushing for Sharia Law. Including Scheer himself who proudly voted against M103 to appease his Rebel scum base.\n",
      "\n",
      "Yet the finger-pointers want to crucify Trudeau and negate all the good he's done over a stupid mistake TWO DECADES AGO???\n",
      " ---------------------------\n",
      "And see this is where we differ ; you are scared for who really are because of the implications, I’m angry because I have to explain to everybody why there should be none. I work with immigrants all day, it’s easy to be open about your gender in liberal places, but try being liberal amongst religious immigrants, it’s fucking tough.\n",
      "\n",
      "For example -\n",
      "\n",
      "Older man doesn’t understand why there is an assortment of gender classifications, guess who knows.\n",
      "\n",
      "Young guy hates black people and immigrants, guess who talks  him through why he hates black people and immigrants , making him realize he just says that stuff for shock value.\n",
      "\n",
      "Older woman thinks women taking over the economy to empower other women is feminism, guess who has to contrast what her perception of feminism with what misogyny is defined as.\n",
      "\n",
      "It becomes exhausting to talk people through concepts they picked up passively over social media and completely misunderstand, leading to cultural misunderstandings.\n",
      "\n",
      "Like a parent who scoffs at another persons child for something their parents made the child do(like myself growing up, had to stay seated during the national anthem).\n",
      "\n",
      "Lots of folks in Ontario with the “lack of energy” to engage. Too many people have their egos attached to their opinion, incapable of feeling like they may not have it right.\n",
      "I love being wrong, It makes me a better person has irritating as it is.\n",
      " ---------------------------\n",
      "No kidding. r/Canada is still going strong, too.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "I was just perma-banned for calling out a user on referring to a George Soros/Jewish conspiracy theory. They said *I* was being racist! [ \n",
      "People on that sub are posting that shit everywhere: \"The Tides Foundation \\[doesn't exist in Canada as Tides Foundation\\] is interfering in Canadian elections!\"\n",
      "\n",
      "Those metacanada mods are in retaliation mode, it seems.\n",
      " ---------------------------\n",
      "Antifa is the propaganda boogeyman of the alt Reich. In any other political climate they'd be considered a fringe group not worth much notice, but in this era they're a useful substitute for hating black/gay/Jewish/trans/Muslim people and therefore get a lot of their social media propaganda directed at them, because they can hate them without being ostracized and pretend like they're doing something positive instead of being the racist shit stains that alt white actually are. It's just their version of being politically correct.\n",
      " ---------------------------\n",
      "I was one of the founding mods of /canada- I did it for about 13 years. I'd say for 8 or 9 years it was just what most people would want in a canada subreddit.  Interesting articles, not too partisan, not a huge amount of moderation involved. \n",
      "\n",
      "And then metacanada started up- at first we thought it was a joke.  At that point I think that we only banned overtly racist or hate posts.  A few /canada mods joined /metacanada without my knowledge, and then shit started going downhill and beyond the resources that mods had to try to contain it.  And one mod that I'd approved and given full permissions to allied with metacanada for a while before I knew it, and by the time I'd banned that person, the damage was done. \n",
      "\n",
      "I do actually blame myself for the shitshow that /canada has become.  There are a lot of people here who care deeply about their country and want to display it and help to make it healthy, but the trolls always get an audience.  Reddit users seem incapable of just ignoring trolls, which means that they get a voice. I'm not a mod of Canada any more, but now I wish that I'd taken the step to be reinstuted.  \n",
      "\n",
      "\n",
      "People can help to reorient the subreddit by posting things about Canada, and refusing to interact with trolls. r/onguardforthee is a great Canadian subreddit- positive and negative posts, with moderated discussions that keep trolls in hand.\n",
      " ---------------------------\n",
      "I don't know what it's like to raise a child, feel an emotional connection to him or her, and see them go down a dark path in life. I have little to no sympathy for people who commit crimes where others are physically harmed, but I'm not someone who can judge a parent for still loving their child after they committed a terrible crime. I recall reading an open letter from the Québec City mosque terrorist's parents and it was quite sad as they explained the intense emotional pain caused by what their son did.\n",
      "\n",
      "With that said, we should never be using double standards when it comes to referring to perpetrators of violence who were politically motivated as \"terrorists\".\n",
      "\n",
      "The Québec City mosque shooter is a terrorist inspired by the alt-right, the 2014 Parliament shooter was a terrorist inspired by radical Islam, the 2014 Moncton shooter who killed RCMP officers is a terrorist inspired by anti-government extremism, the 1989 Polytechnique shooter was a terrorist inspired by misogyny, the Front de libération du Québec (FLQ) were a terrorist group in the 1960s and 1970s who used violence to promote Québec as a socialist state separate of Canada. Full stop.\n",
      " ---------------------------\n",
      "&gt;Premier Ford has a net favourability rating of -53.5%. By comparison, Wynne’s net favourability rating stood at -35.3% on April 30th, 2018.\n",
      "\n",
      "Wow...\n",
      "\n",
      "I know it can be depressing as a progressive voter to see province after province elect a conservative government, but it was always my opinion that Canada tends to swing back and forth between electing liberals and conservatives, with the latter being over-represented due to our archaic first-past-the-post voting system where the centre to left vote is split.\n",
      "\n",
      "It hurts to say it, but Ontario is getting what it deserves for voting for a former drug distributor who enabled his brother's hard drug addiction while running his sign company into the ground. It just seemed like so much of the Wynne hatred was just a \"gut feeling\" as opposed to actual criticisms of her policies. The next three years will remind voters that voting out of spite has consequences as I expect further cuts into much needed public programs.\n",
      " ---------------------------\n",
      "As an Albertan who has volunteered for the Alberta Liberals and NDP over the years and the Federal Liberal Party as well- Please stop being an asshole.\n",
      "\n",
      "That constant shitting on Alberta by other Canadians as if everyone is some Redneck American Republican, including millions of people who have voted left wing in the past and probably will in the future, simply makes the Conservative parties that prey on ROC-vs-Alberta conflict more appealing.\n",
      "\n",
      "The same goes for snide remarks about Quebec.\n",
      "\n",
      "**That attitude is not wanted, helpful, or needed. It helps the right-wingers that you seem to hate so much.**\n",
      "\n",
      "Seriously, what compels you to make such remarks? What do you get out of it?\n",
      " ---------------------------\n",
      "Watched this video yesterday and thought it was quite good. This young guy explains what attracted him to the alt-right, and how he managed to finally break free of the brainwashing.\n",
      "\n",
      "The Canadian connection here is that he was first introduced to fascist ideology, like many others, through Stefan Molyneux videos on YouTube. His description of the alt-right as a \"cult\" is dead on, considering that Molyneux is literally a cult leader, [one who enlisted the help of his therapist wife]( to brainwash unsuspecting clients and extract money from them:\n",
      "\n",
      "&gt;The College of Psychologists of Ontario found Ms. Papadopoulos guilty of professional misconduct in November, 2012, faulting her for adopting Mr. Molyneux's views and using the Internet to counsel people to sever ties with their families.\n",
      "\n",
      "&gt;A civil court complaint filed on Oct. 24 in California says Mr. Molyneux boasted in a 2006 podcast that he would listen while his wife talked with her patients, even interjecting and suggesting they sign up with his website.\n",
      "\n",
      "His organization uses [tactics similar to the Church of Scientology]( where followers are encouraged to cut all ties with their non-believer friends and family:\n",
      "\n",
      "&gt;Members also talk about FOO (family of origin) and deFOO (leaving the family of origin). For example, Laura's husband, Stephen, shared news of his breakup with his family in a posting titled: \"DeFoo letter to my father .\"\n",
      " ---------------------------\n",
      "I absolutely agree with you on all points. Trump being elected should be a wake up call as to the dangers of populism and the deep wells of prejudice that still exist in our society - it's become (debatably) less socially acceptable to be outright hateful but that doesn't mean the bigotry has gone away. Heck, it was a wake up call for me and I am a queer woman who suffered from homophobia in a very conservative community growing up and did an anthropology degree that focused to a large extent on the treatment, historically and presently, of indigenous peoples in Canada. To continue to ignore the warning signs of underlying prejudices and how politicians like Trump (and Hitler... not to make comparisons...) take advantage of it to promote their extremist agendas is perilous. There's a lot of anger directed at marginalized people for the perceived disadvantages any progress in favour of a more equitable world has caused. People feel entitled to their privilege, and giving any ground to people who suffer systemic marginalization become interpreted as oppression, and then anger over this perceived injury just boils over. It's dangerous to underestimate it.\n",
      " ---------------------------\n",
      "This is one of the most downvoted communities of all time and there is transparent vote manipulation and downvote attempts that aim to suppress unwelcome opinions. It's patently obvious the sub doesn't represent the full range of Canadian experiences when people like Doug Ford are praised and critical comments of him are aggressively attacked and down-voted - when polls show that the majority of Ontarians dislike his government.\n",
      "\n",
      "I don't necessarily subscribe to the Russians are behind this narrative, but rather to personal and professional actors with vested agendas alike are active on that sub, and use it as an oppourtunity to push and frame narratives.\n",
      "\n",
      "This is unfortunate because it reduces the Canadian identity and presence on reddit to a confrontational style arena where the objective is to ideologically destroy opponents, limiting the space for conciliation, discussion, and frankly a celebration of the Canadian identity.\n",
      "\n",
      "It hurts to see my country portrayed in this way.\n",
      " ---------------------------\n",
      "&gt; Maybe it's because everyone is cooped up indoors and getting restless, anxious, etc., but it feels like there's a significant portion of Reddit that has straight up devolved to parroting propaganda, trolling, bigotry.\n",
      "\n",
      "Perhaps part of it is that there isn't external agency pushback to the user's held belief, due to lockdown. Take, for instance, the work-at-home users right now. Left or right, many work in multi-spectrum workplaces, where a held belief is both confirmed and challenged during the social times in the workplace.\n",
      "\n",
      "Removed from that scene, a held belief isn't going to receive the same challenge, because the belief holder (left wing for example) isn't going to search out right wing news / opinion sites, nor will the opposite. Without the real-life challenges to our beliefs, we become more susceptible to the oft-used 'echo chamber'.\n",
      "\n",
      "While I don't suggest venturing into shit holes like metacanada to look for an opposing opinion, I strongly recommend finding someone who can be dispassionate and play the teapot's advocate to challenge one's own beliefs, if for nothing else, than to keep yourself from falling victim to echo chamberitis.\n",
      " ---------------------------\n",
      "If I can explain myself: this is the only subreddit of those mentioned that claim to not allow bigotry or hate and to also claim by their action having the moral high ground and  allow themselves to call out other Canadian sub on their racism and bigotry (which is something I agree on, we definitely should call out bigotry and racism)\n",
      "\n",
      "Therefore, I expected this sub and the people on it to uphold themselves to respect this standard. Yet scrolling through these comments, I saw a lot of hate, miss information, bigotry and assumption on what happened and not searching further than the headline. Witch  disappointed me as I expected better from this sub.\n",
      "\n",
      "  \n",
      "So yeah, it's the mix of blatant hate, bigotry and of my expectation of this sub that made me feel more disgusted than I've felt scrolling through any post on [r/canada]( or [r/metacanada]( \n",
      "TL:DR : My bad, shouldn've had high expectation from a subreddit.\n",
      " ---------------------------\n",
      "yeah i know, theyve done that to me countless times til i got banned. its a specific cultivation of opinions they want to see and hear.\n",
      "\n",
      "what im trying to say is the /canada mods are in support of this, all of them. they let /medym in and he took over. now the default canadian sub is run by racist rightwing assholes that think skinny white boys in the STEM fields are the only real oppressed minority. basically the worst kind of reddit user is now the only person whos likely to be heard out on that shit hole.\n",
      "\n",
      " /torontos not much better: a pack of police-bootlicking, rich-developer-ass-kissing, \"blackface is just personal expression\" trolls and contrarians who exemplify torontos stereotype of \"the screwface capital\" by acting as if anyone that cares about anything is just trying too hard.\n",
      "\n",
      "theres this bitter little core of people that influences all of reddit: \n",
      "\n",
      "the sort of person that got their beliefs from south park,\n",
      "\n",
      "the sort of person that uses \"tryhard\" or \"cringe\" as if they were grievous insults, \n",
      "\n",
      "the sort of person for whom memes and racist jokes are the highest form of expression.\n",
      "\n",
      "the sort of person that shows disgust towards any belief that isnt wrapped in jaded centrism and mean jokes\n",
      "\n",
      "the sort of person for whom free speech means a bunch of bigoted jokes that need to be told lest the communists censor us all!\n",
      "\n",
      "fucking useless libertarian centrist nazi-enabling twats refuse to listen to anyone that isnt constantly stroking their egos.\n",
      "\n",
      "if you cant tell, im a bit annoyed by the whole thing\n",
      " ---------------------------\n",
      "What a fucking disgrace. Ford is just going to parrot whatever the Fascist Mango does, isn't he?\n",
      "\n",
      "That they ACTUALLY stood up and called gender identity a \"liberal ideology\" shows just how deeply the language of the alt-right is leeching into our politics. These clowns sound like a /r/metacanada user posting a hot take to rationalize their bigotry while they wait for their mom to bring fresh chicken tendies to the basement, not functional adults who have the capacity to lead a province.\n",
      " ---------------------------\n",
      "&gt; Why are we constantly being told that we are supposed to ignore the stated personal beliefs of right-wing politicians and the people they choose to work with and for? \n",
      "\n",
      "Because, silly. If we ignore them, they can follow through with them and claim \"well, nobody objected!\"\n",
      "\n",
      "If ANYONE thinks far-right zealotry is confined to the USA or that it will stop at attacking reproductive rights, they're incredibly wrong.\n",
      "\n",
      "The far right has a long list of enemies. They've not forgotten about \"the gays\" either. Jason Kenney is happily attacking them in Alberta as we speak.\n",
      "\n",
      "Social conservatism is cancer and needs to be irradiated quickly before it spreads.\n",
      " ---------------------------\n",
      "If the UCP/right wing/alt-right think we're going away,  *I have bad news for them*.  \n",
      "\n",
      "I want everyone to have quality health care,  education and reasonable taxation.   I loathe and despise bigotry towards gay, lesbian and transgendered albertans.\n",
      "\n",
      "I will not accept hatred of minorities because they have a different skin color,  nor will I blame our issues on immigrants. \n",
      "\n",
      "I will not accept candidates (or now MP's) who have been caught parroting white supremacist talking points.   They are just as illegitimate as the people who are now being investigated by the RCMP for voter fraud.   \n",
      "\n",
      "Climate change is real and this election doesn't change that.    \n",
      "\n",
      "This isn't about my side winning or in this case losing tonight,  this about the long game,  fighting for rights that we should all enjoy and respect.\n",
      "\n",
      "The pseudo-libertarian ideology that Kenney and co. have is dangerous and will not address the innumerable market externalities that we now collectively face.\n",
      "\n",
      "And finally,  the PC's ruled this province for 40 years,  with literally zero competition.  It was never close until 2015,  but thanks to Kenney's bigotry (GSA's,  abortion comments,  tacit support of white supremist MLA's) we now have a *very strong progressive movement in this province* that isn't in the shadows any longer.   Consider the political and historical context of the last 40 years,  and the NDP numbers are far, far more impressive that it may appear tonight.\n",
      " ---------------------------\n",
      "This is a very unpopular opinion,  especially amongst progressives,  but in my view,  **we need to unify the left**.\n",
      "\n",
      "The days of socially liberal(ish) conservatives like Kim Campbell, Mulroney etc  are **long, long gone**.  \n",
      "We now have shitstains like Bobandy in Alberta and Sheerer kissing Faith Goldy's rotten ass.   The literal head\n",
      "of the conservatives was making nice nice with a fucking white supremacist. \n",
      "\n",
      "So,  we could talk about how we don't want a two party system like the US.  We could talk about how we all have choices.\n",
      "We could make a million fucking reasons about why we should have two or three fucking center / center-left parties.  \n",
      "\n",
      "But in the end,  if we keep that up,   we will fuck ourselves when Sheerer gets 8 or 12 years of running this country.\n",
      "\n",
      "Alberta only elected the NDP **because the right was fractured**.   They figured that shit out real quick didn't they?\n",
      "\n",
      "Politics is often about choosing the lesser evil,  and right now we can either suck it up or get literal fascists running our country like the US.\n",
      " ---------------------------\n",
      "&gt; There is a difference between sex and gender, which is what makes us trans women actually women\n",
      "\n",
      "Nah, this is merely a function of left-leaning bias in Universities, it's not truth, it's just the contemporary left-wing dogma, a sort of social constructionist viewpoint.\n",
      "\n",
      "Everyone has a mental conception of what they are, that can align with physical reality or not.  Sex is a physical reality, from macroscopic organs to microscopic chromosomes.  There are a finite number of chromosomal mutations that produce intersexed offspring that survive to full term and get born.  This is all well-settled science.\n",
      "\n",
      "So, I might think that I am an elm tree, but this does not mean that even though I am physioloigcally a human, I am ideologically an elm tree and that ideology should prevail. If I think I am an elm tree, obviously I am not perceiving reality correctly.  Now, some things are going to be subjective, like \"is that a beautiful painting?\" then we do have disagreement amongst art critics, and, in the end, an individual who says \"yes\" and one who says \"no,\" neither one is wrong, because beauty is not a physical thing like sex.  Gender is not like some artistic criticism of a body, and this \"gender is not sex\" is a thing rooted in queer theory, designed to \"disrupt the binary,\" that's all it is.\n",
      "\n",
      "So, no, you're not actually women any more than I am actually an elm tree because I feel myself to be one.  You're a man who may enjoy wearing dresses, taking hormones, doing whatever, I don't care, but this doesn't change your ontological status: being is defined by physics, not by your own personal ideology.\n",
      " ---------------------------\n",
      "&gt; McInnes, a Vice co-founder who left the magazine in 2008, created the Proud Boys, their rules and membership tiers, including a fourth degree reserved for Proud Boys who get in a fight “for the cause.” But McInnes, who regularly appears at Proud Boy events and initiations, claimed in the new video that he was never the group’s leader.\n",
      "\n",
      "\"I'm creator, founder, director, president, CEO, COO, CFO, DDS, ABC, and MSG. I wrote all the rules and created the membership levels and even give the golden buttplug to the level 4 incels, but I am *not* the leader. Dave. Dave over there? Yeah, he's the leader.\"\n",
      "\n",
      "These fucking people. It's all hate and hate games until the FBI classifies you as a hate group.\n",
      " ---------------------------\n",
      "Citations Needed is beast.  Everyone should join  /r/CitationsNeeded\n",
      "\n",
      "[The myth of the middleclass]( like most mythology, only serves to obscure power relations and serve those in power.  If you fear falling into the lower class, you are more obedient at work.  If you have anxiety over not having the lifestyle of the upper class,  you will have insecurities that lead you to be a proper consumer.  \n",
      "\n",
      "Within the modern secular conception of virtue and vice, we can see wealth as heaven and poverty as hell.  Those who have succeeded and those that are failing each of their own devices detached from history or social context.  Residual Christian ontology still serves as the ideological rationalization for class stratification.   \n",
      " No one wants to consider themselves a secular sinner so the concept of middleclass serves as a kind of purgatory where the mediocrity imposed by austerity politics traps people.  \n",
      "\n",
      "Unless you can pay the indulgences and get into heaven hastily.  Capital Reformation when?\n",
      " ---------------------------\n",
      "You are right about the attitude towards addiction but you are wrong about it being a core of conservatism. \n",
      "\n",
      "I was raised by parents who voted conservative most of their life, they didn’t do it to screw over others. They were and still are poor but that never stopped them from helping others in need or distress. They would help in their communities, often through church organizations, despite the wealthier and more influential people there shunning them. Painting all conservatives as heartless does a disservice to convincing those who do have good hearts that by voting for how they remember how the conservatives used to be means they are working counter to their charitable, community driven efforts by who the conservatives are currently whose strict adherence to ideology based policies hurts the side of Canadians conservatism that cares about their communities.\n",
      "\n",
      "That is to say in summing this up, I am not saying “not all conservatives”, I am saying that as someone who used to vote conservative, as they currently have constituted themselves in words and in deeds, I can not in good conscience vote for the conservatives as they existed under Harper, Scheer, and especially not Bernier. Your saying conservatives lack compassion as a core value would put conservative voters, who have yet to come to the same position as I find myself, on the defensive because they understandably would see your comment as attacking a part of their identity, which our psyche can’t help but double down on. Please try to find a better way to express that conservative policies are harmful than telling someone else what their core is, it may not have the outcomes that actually help us.\n",
      " ---------------------------\n",
      "Is it silly? Yes. Petty, sure, but I and the left have been called communist by the right for decades despite the fact that nether I nor the left in general are any such thing. \n",
      "\n",
      "The right, on the other hand have regularly called for policies that could rightly be called fascist. I remember when AIDS was first discovered, many on the right called for all gays people to be shipped away to quarantine camps or just killed outright. The right regularly call the CBC the Communist Broadcasting Corporation. There is a growing alt right/neo-Nazi presence in Canada openly calling for the expulsion of anyone not white. The right *actually* has a fascism problem. The left does *not* have a totalitarianism problem. And before you claim that antifa is somehow totalitarian, it is literally anti-fascist, not pro anything. It exists only to fight fascism. Conservatives could join it if they were serious about fighting that problem. But instead of fighting it, people like Jordan Peterson actually soften the ground for fascists with his \"cultural marxism\" conspiracy rhetoric and his outright, alarmist lies about the left and the law in Canada.\n",
      " ---------------------------\n",
      "The Youtube comments makes a good point: the people within the Canadian Yellow Vests movement that aren't in it for immigration or mostly for pipelines, etc. haven't done much to speak out against these Nazis within their movement.  In fact, I would argue they are enabling them: I have seen posts about how free speech is being labeled as \"hate speech\", etc.  I have also seen the same Sikh yellow vester getting re-posted over and over on their Facebook group, almost as if they have to assure themselves there is no racism within the movement.  \n",
      "\n",
      "I have heard anecdotes of open white nationalists at the Edmonton rally, I think anyone non-white should be wary about Yellow Vest movement in Canada, even if you are in it for economic reasons, etc.  \n",
      " ---------------------------\n",
      "You don't have to dig too deeply to realize that **'It's Okay To Be White' actually means 'THEY think it's NOT okay to be white'.**\n",
      "\n",
      "It's part of the ongoing effort to increase sectarianism and anti-Democratic othering and I wouldn't be shocked to discover that this another one of those examples of the Russians whipping up their useful idiots into a frenzy without the locals realizing that they're being coopted into a foreign anti-Democracy PsyOps campaign.\n",
      "\n",
      "\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n",
      "\n",
      "EDIT: A guy doubted me and then deleted his comment... so I'll just post the 'evidence' part of my response to him here\n",
      "\n",
      "[Russia organized 2 sides of a Texas protest and encouraged 'both sides to battle in the streets']( \n",
      "[Russian trolls orchestrated divisive protests in the US about Trump — here are 9 that we know about](https://www.businessinsider.com/russians-organized-pro-anti-trump-rallies-to-sow-discord-2018-2/)\n",
      " ---------------------------\n",
      "\" Dude wore MAGA hats and worshipped Trump.  \"\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "Bernie supporters voted for Trump over Hillary.  What part of this scares and confuses you?\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      " Bissonnette  's facebook page was super leftist, Google: \"Alexandre Bissonnette ndp\" if you can muster the brain power to use Google.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "NDP is a far left wannabe-communist party that varies greatly on stances province to province and Federally in the nation of Canada.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "He supported them his whole life and even today he still does... that makes him a leftist.  Case closed.  \n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "Trump is the most left elected Republican President since Reagan... you might even say that the Republican party was hijacked by Reagan and Trump.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "Even the \"Make America Great Again\" slogan is from Reagan for fucks sake, all you dumb millennials and teenagers didn't get that. because you are too stupid to use Google to learn.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "&amp;#x200B;\n",
      " ---------------------------\n"
     ]
    }
   ],
   "source": [
    "for comment in top_ogft:\n",
    "    print(comment + \"\\n ---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest Probability r/Canada Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serious answer? \n",
      "\n",
      "1. Huawei is the only vendor that is currently able to roll out 5G tech on a commercial scale and at a much cheaper price than its competitors. You can blame tech stealing or whatever, but those are the facts. Banning Huawei would essentially give the rest of the world a head start in the 5G game. \n",
      "\n",
      "2. Huawei is already being used extensively in 4G networks by Telus and Bell. So if we ban Huawei entirely, we would have to rip out a lot of the current mobile infrastructure as well.\n",
      "\n",
      "3. There is currently no evidence of any backdoors to Huawei equipment. Of course this doesn't mean that they can't do it later on, but everything so far including the Nortel case and the microchip case by bloomberg have basically all been based on hearsay. \n",
      "\n",
      "4. Huawei has multi-million dollar research agreements with UT and UBC. \n",
      "\n",
      "Or if you're r/Canada:\n",
      "\n",
      "1. Trudeau has been bought by the Chinese. \n",
      "\n",
      "What are the security risks:\n",
      "\n",
      "1. Huawei has a history of cyber-industrial espionage. I personally *believe* the Nortel case to be true because from my perspective it would be stupid for Huawei not to have donen it. When Nortel went under, a lot of engineers and techies would have been looking for new sources of income. After all, they just lost their jobs. It wouldn't have been very difficult for Huawei to simply hire them afterwards and then who knows what information they shared. That doesn't mean there is \"proof\". I've seen a lot of the several year old Nortel article being spread around, but everybody seems to ignore the fact that it literally says that there is no proof right in the middle of the article. I doubt anybody even read it. \n",
      "\n",
      "2. China has a law that says Chinese companies must share security information with the government if requested. So legally speaking, if China hypothetically asked Huawei to provide information, they would have to. \n",
      "\n",
      "3. Huawei users will be dependent on Chinese equipment. We already are, but even more so. \n",
      "\n",
      "4. According to the Snowden leaks, the US hacked Huawei servers and intended on using Huawei hardware to spy on targets such as Iran, Afghanistan, Pakistan, Kenya, Cuba. Since Huawei is being banned in the Five Eyes, this might indicate that recent US operations have not been so successful, but you can't rule out that the US isn't spying on you with Huawei products either. So you'll likely have both China and the US monitoring you at the same time. \n",
      "\n",
      "EDIT: I would like to say that I don't disagree that Huawei is a security risk. This is simply pointing out why Canada would hesitate to just say \"hey we don't want you hear anymore, get lost\" on a moment's notice. \n",
      " ---------------------------\n"
     ]
    }
   ],
   "source": [
    "for comment in top_can:\n",
    "    print(comment + \"\\n ---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainly classified comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's there for people on the fence thinking about the value of their savings and feeling any guilt for not donating. They actually have donated via the method I mentioned above so there should be no guilt for refusing to donate. That also allows them to complain about the situation regardless of not fitting OP's definition of what a donation is.\n",
      " ---------------------------\n",
      "Once again. You said that for the past 60 days, give or take, Trudeau has been failing. 10 days ago the WHO praised the response. You're an idiot.\n",
      " ---------------------------\n",
      "I've never seen Cortland over here, but I'll keep the name in mind.  Thanks!\n",
      " ---------------------------\n",
      "That's like saying \"Let's steal all the stop signs at this intersection and see how long it takes before people don't stop there.\"\n",
      "\n",
      "You can't trick people into thinking you've done a thing by actually doing the thing. That's not a trick. It's just you doing the thing.\n",
      " ---------------------------\n",
      "It's worth noting that UBC only allowed the hosting of the speaker by a campus group. They did not invite them or endorse them. So apparently if you don't actively suppress ideological opponents you're an enemy of the cause.\n",
      " ---------------------------\n",
      "Shocked the only got 49 Mil tbh\n",
      " ---------------------------\n",
      "Zero tolerance unless it affects us. Now I understand.\n",
      " ---------------------------\n",
      "Also [McMaster students and former post-doctoral fellow killed on Flight PS752](https://www.thespec.com/news-story/9801071-update-former-mcmaster-post-doctoral-fellow-two-students-confirmed-killed-in-tehran-plane-crash/)\n",
      " ---------------------------\n",
      "In fairness we might not see the effects for a few weeks, because it only just started. It might still not do anything though, I don't know.\n",
      " ---------------------------\n"
     ]
    }
   ],
   "source": [
    "for comment in uncertain_comments['body_processed']:\n",
    "    print(comment + \"\\n ---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Analysis (By Model Probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogft_log_probs=bnb_final[1].feature_log_prob_[1]\n",
    "canada_log_probs=bnb_final[1].feature_log_prob_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 12.,  7., ...,  6., 48., 10.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_final[1].feature_count_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs = pd.DataFrame(bnb_final[0].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs['ogft_log_prob']= ogft_log_probs.transpose()\n",
    "token_probs['canada_log_prob']= canada_log_probs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs.columns = ['token', \"ogft_log_prob\", \"canada_log_prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs['odds_gap'] = np.abs(token_probs['ogft_log_prob']-token_probs['canada_log_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs['favoured']=token_probs.apply(lambda x: \"r/OnGuardForThee\" if x['ogft_log_prob'] > x['canada_log_prob'] else \"r/Canada\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs['ogft_count']=bnb_final[1].feature_count_[1]\n",
    "token_probs['canada_count']=bnb_final[1].feature_count_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs.set_index('token', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs= token_probs[['ogft_count', 'canada_count', 'ogft_log_prob', \"canada_log_prob\", \"odds_gap\", \"favoured\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique/strongly favoured tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**: Let's look at tokens that were modeled to strongly favour one subreddit over the other by looking by the gap in odds between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/Canada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogft_count</th>\n",
       "      <th>canada_count</th>\n",
       "      <th>ogft_log_prob</th>\n",
       "      <th>canada_log_prob</th>\n",
       "      <th>odds_gap</th>\n",
       "      <th>favoured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>impair</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.087042</td>\n",
       "      <td>2.848598</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meng</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.281198</td>\n",
       "      <td>2.654442</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marineland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.522360</td>\n",
       "      <td>2.413280</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burger</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-5.829213</td>\n",
       "      <td>2.413280</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disciplin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.617670</td>\n",
       "      <td>2.317970</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naturopath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>2.212609</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telecommun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>2.212609</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>2.212609</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>2.212609</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>2.212609</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>egg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.029884</td>\n",
       "      <td>2.212609</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taiwan</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.087042</td>\n",
       "      <td>2.155451</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huawei</th>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-7.143881</td>\n",
       "      <td>-5.028435</td>\n",
       "      <td>2.115446</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.840814</td>\n",
       "      <td>2.094826</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.840814</td>\n",
       "      <td>2.094826</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquarium</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.840814</td>\n",
       "      <td>2.094826</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.147667</td>\n",
       "      <td>2.094826</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>escal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.974345</td>\n",
       "      <td>1.961295</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>captiv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.974345</td>\n",
       "      <td>1.961295</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realtor</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-6.974345</td>\n",
       "      <td>1.961295</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launder</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-7.837028</td>\n",
       "      <td>-5.875733</td>\n",
       "      <td>1.961295</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discount</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.355306</td>\n",
       "      <td>1.887187</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wireless</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-7.128496</td>\n",
       "      <td>1.807144</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nortel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-7.128496</td>\n",
       "      <td>1.807144</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transact</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.522360</td>\n",
       "      <td>1.720133</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condo</th>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-7.549346</td>\n",
       "      <td>-5.829213</td>\n",
       "      <td>1.720133</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.617670</td>\n",
       "      <td>1.624823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.617670</td>\n",
       "      <td>1.624823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beaver</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.617670</td>\n",
       "      <td>1.624823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monopoli</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-7.837028</td>\n",
       "      <td>-6.212205</td>\n",
       "      <td>1.624823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grad</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.617670</td>\n",
       "      <td>1.624823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gdp</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-7.549346</td>\n",
       "      <td>-5.924523</td>\n",
       "      <td>1.624823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unlimit</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-7.837028</td>\n",
       "      <td>-6.281198</td>\n",
       "      <td>1.555830</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netflix</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-7.837028</td>\n",
       "      <td>-6.281198</td>\n",
       "      <td>1.555830</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fentanyl</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-7.837028</td>\n",
       "      <td>-6.281198</td>\n",
       "      <td>1.555830</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bridg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alaska</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>porn</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obstruct</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tangibl</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dairi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starter</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retain</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lte</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oligopoli</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.519462</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydro</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-7.549346</td>\n",
       "      <td>-6.087042</td>\n",
       "      <td>1.462304</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plea</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.840814</td>\n",
       "      <td>1.401679</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigarett</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.242493</td>\n",
       "      <td>-6.840814</td>\n",
       "      <td>1.401679</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-8.935640</td>\n",
       "      <td>-7.533961</td>\n",
       "      <td>1.401679</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanction</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-7.549346</td>\n",
       "      <td>-6.147667</td>\n",
       "      <td>1.401679</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ogft_count  canada_count  ogft_log_prob  canada_log_prob  \\\n",
       "token                                                                  \n",
       "impair             0.0          16.0      -8.935640        -6.087042   \n",
       "meng               0.0          13.0      -8.935640        -6.281198   \n",
       "marineland         0.0          10.0      -8.935640        -6.522360   \n",
       "burger             1.0          21.0      -8.242493        -5.829213   \n",
       "disciplin          0.0           9.0      -8.935640        -6.617670   \n",
       "naturopath         0.0           8.0      -8.935640        -6.723031   \n",
       "telecommun         0.0           8.0      -8.935640        -6.723031   \n",
       "brazilian          0.0           8.0      -8.935640        -6.723031   \n",
       "taxi               0.0           8.0      -8.935640        -6.723031   \n",
       "xi                 0.0           8.0      -8.935640        -6.723031   \n",
       "egg                1.0          17.0      -8.242493        -6.029884   \n",
       "taiwan             1.0          16.0      -8.242493        -6.087042   \n",
       "huawei             5.0          48.0      -7.143881        -5.028435   \n",
       "dst                0.0           7.0      -8.935640        -6.840814   \n",
       "bond               0.0           7.0      -8.935640        -6.840814   \n",
       "aquarium           0.0           7.0      -8.935640        -6.840814   \n",
       "gb                 1.0          15.0      -8.242493        -6.147667   \n",
       "escal              0.0           6.0      -8.935640        -6.974345   \n",
       "captiv             0.0           6.0      -8.935640        -6.974345   \n",
       "realtor            0.0           6.0      -8.935640        -6.974345   \n",
       "launder            2.0          20.0      -7.837028        -5.875733   \n",
       "discount           1.0          12.0      -8.242493        -6.355306   \n",
       "wireless           0.0           5.0      -8.935640        -7.128496   \n",
       "nortel             0.0           5.0      -8.935640        -7.128496   \n",
       "transact           1.0          10.0      -8.242493        -6.522360   \n",
       "condo              3.0          21.0      -7.549346        -5.829213   \n",
       "tick               1.0           9.0      -8.242493        -6.617670   \n",
       "seal               1.0           9.0      -8.242493        -6.617670   \n",
       "beaver             1.0           9.0      -8.242493        -6.617670   \n",
       "monopoli           2.0          14.0      -7.837028        -6.212205   \n",
       "grad               1.0           9.0      -8.242493        -6.617670   \n",
       "gdp                3.0          19.0      -7.549346        -5.924523   \n",
       "unlimit            2.0          13.0      -7.837028        -6.281198   \n",
       "netflix            2.0          13.0      -7.837028        -6.281198   \n",
       "fentanyl           2.0          13.0      -7.837028        -6.281198   \n",
       "bridg              1.0           8.0      -8.242493        -6.723031   \n",
       "alaska             1.0           8.0      -8.242493        -6.723031   \n",
       "porn               1.0           8.0      -8.242493        -6.723031   \n",
       "obstruct           1.0           8.0      -8.242493        -6.723031   \n",
       "tangibl            1.0           8.0      -8.242493        -6.723031   \n",
       "dairi              1.0           8.0      -8.242493        -6.723031   \n",
       "starter            1.0           8.0      -8.242493        -6.723031   \n",
       "retain             1.0           8.0      -8.242493        -6.723031   \n",
       "lte                1.0           8.0      -8.242493        -6.723031   \n",
       "oligopoli          1.0           8.0      -8.242493        -6.723031   \n",
       "hydro              3.0          16.0      -7.549346        -6.087042   \n",
       "plea               1.0           7.0      -8.242493        -6.840814   \n",
       "cigarett           1.0           7.0      -8.242493        -6.840814   \n",
       "nl                 0.0           3.0      -8.935640        -7.533961   \n",
       "sanction           3.0          15.0      -7.549346        -6.147667   \n",
       "\n",
       "            odds_gap  favoured  \n",
       "token                           \n",
       "impair      2.848598  r/Canada  \n",
       "meng        2.654442  r/Canada  \n",
       "marineland  2.413280  r/Canada  \n",
       "burger      2.413280  r/Canada  \n",
       "disciplin   2.317970  r/Canada  \n",
       "naturopath  2.212609  r/Canada  \n",
       "telecommun  2.212609  r/Canada  \n",
       "brazilian   2.212609  r/Canada  \n",
       "taxi        2.212609  r/Canada  \n",
       "xi          2.212609  r/Canada  \n",
       "egg         2.212609  r/Canada  \n",
       "taiwan      2.155451  r/Canada  \n",
       "huawei      2.115446  r/Canada  \n",
       "dst         2.094826  r/Canada  \n",
       "bond        2.094826  r/Canada  \n",
       "aquarium    2.094826  r/Canada  \n",
       "gb          2.094826  r/Canada  \n",
       "escal       1.961295  r/Canada  \n",
       "captiv      1.961295  r/Canada  \n",
       "realtor     1.961295  r/Canada  \n",
       "launder     1.961295  r/Canada  \n",
       "discount    1.887187  r/Canada  \n",
       "wireless    1.807144  r/Canada  \n",
       "nortel      1.807144  r/Canada  \n",
       "transact    1.720133  r/Canada  \n",
       "condo       1.720133  r/Canada  \n",
       "tick        1.624823  r/Canada  \n",
       "seal        1.624823  r/Canada  \n",
       "beaver      1.624823  r/Canada  \n",
       "monopoli    1.624823  r/Canada  \n",
       "grad        1.624823  r/Canada  \n",
       "gdp         1.624823  r/Canada  \n",
       "unlimit     1.555830  r/Canada  \n",
       "netflix     1.555830  r/Canada  \n",
       "fentanyl    1.555830  r/Canada  \n",
       "bridg       1.519462  r/Canada  \n",
       "alaska      1.519462  r/Canada  \n",
       "porn        1.519462  r/Canada  \n",
       "obstruct    1.519462  r/Canada  \n",
       "tangibl     1.519462  r/Canada  \n",
       "dairi       1.519462  r/Canada  \n",
       "starter     1.519462  r/Canada  \n",
       "retain      1.519462  r/Canada  \n",
       "lte         1.519462  r/Canada  \n",
       "oligopoli   1.519462  r/Canada  \n",
       "hydro       1.462304  r/Canada  \n",
       "plea        1.401679  r/Canada  \n",
       "cigarett    1.401679  r/Canada  \n",
       "nl          1.401679  r/Canada  \n",
       "sanction    1.401679  r/Canada  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_probs[token_probs['favoured']=='r/Canada'].sort_values('odds_gap', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few of these that can be sorted into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most skewed token by odds is **impair**. Apparently r/Canada is much more concerned about impaired driving issues than OnGuardForThee. A quick search reveals that they had a lot of discussion about impaired driving laws as relating to weed legalization.\n",
    "\n",
    "Issues to relating to China: \"meng\", (Meng Whenzhou), \"xi\" (Xi JingPing), \"huawei\" and \"taiwan\".\n",
    "\n",
    "\"marineland\" and \"aquarium\". Niagara's controversial aquarium.\n",
    "\n",
    "Telecommmunications: \"telecommun\", \"nortel\", \"wireless\", \"unlimit\" (probably). Complaining about the telecommunications cartel is a long standing Canadian pastime.\n",
    "\n",
    "Real estate: \"realtor\", \"launder\", \"condo\", \"transcat\".\n",
    "\n",
    "In general, our model thinks that r\\Canada likes talking about China-Canada relations and business issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm really not sure what's going on with the \"burger\" keyword, so let's do a quick search and see what they're talking about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Burger references in training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something to be said for no cholesterol though I think.  I wish they'd pick a random group of non-insulin resistant people with normal cholesterol/body weight and give them some beyond burgers to eat and give a control group some beef burgers and then check out their cholesterol after a period of time.  It doesn't seem like it should be that difficult\n",
      " ______________________\n",
      "More like Canada’s most iconic brand has now decided to butcher hamburgers along with the rest of their terrible food.\n",
      " ______________________\n",
      "Gotta add pork fat or something or that is gonna be one dry burger.\n",
      "\n",
      "Plus fat is good for you.\n",
      " ______________________\n",
      "Ya'll can't toast and butter a bagel correctly. \n",
      "\n",
      "Why are you serving burgers and spicy Thai soup?\n",
      " ______________________\n",
      "I'll stick with A&amp;W for my beyond burgers.\n",
      " ______________________\n",
      "Eating beyond burgers is a political statement not a health choice. I wish they would advertise it that way and not confuse the public.\n",
      " ______________________\n",
      "The fact his coworkers reported his social media to CPS is the little piss pickle on top of this shitburger\n",
      " ______________________\n",
      "Maybe the oil workers who somehow think their jobs are going to magically appear again overnight won't have to hook for cheeseburgers now.\n",
      " ______________________\n",
      "The burger thinks it's clever\n",
      " ______________________\n",
      "the minute you can get frozen beyond burgers cheaper than frozen hamburgers is when you'll see a huge shift. When people are buying the cheapest meat they're not looking for quality, currently it probably already has a bunch of soy filler that they don't need to list as an ingredient (if less than 2% total protein they only need to put \"contains soy\").\n",
      "\n",
      "With this huge vegan/plant based shift all you hear is, \"this is bad for the dairy farmers\" or \"this is bad for the cattle farmers\". Meanwhile Canada is the largest producer of lentils in the world and most Canadians have never even eaten one.\n",
      "\n",
      "Plus, beyond meat is making no claims about being a healthier alternative. I mean, yes, you avoid the carcinogenic properties of red meat and heterocyclic amines and nitrates in processed meats, but you still have a patty loads in sodium and saturated fat. A lot of people are making the comparision of the beyond burger to a 90/10 burger when in reality it's more like a fast food burger. When you compare those options, yes, the beyond burger is \"healthier\" but still not something you should eat on a regular basis.\n",
      " ______________________\n",
      "One of the shitty popular Canadian branded coffee shops in my town brought in all TFW workers.  They reasoned that they couldn’t bring in Canadian workers because no one will work for their wages due to the oil patch and high cost of living.  The unfortunate thing is high school students applied and couldn’t or wouldn’t get hired by this manager.  The Canadian staff that was there left eventually because their hours dropped and they were treated poorly till they left.  Turns out the manager didn’t like the current staff telling the new staff things like labour laws and their rights.  The town became upset and people bitched but no one stopped lining up for shitty coffee and thawed from frozen doughnuts.  Several well known chains did this.  One family burger chain even had people stacked like sardines living in a shitty rental for a huge chunk of their pay cheque.  People that take advantage of foreign workers are such scum.\n",
      " ______________________\n",
      "Oh man I love Beyond Burgers and regular burgers, but Beyond gives me the most wicked burps\n",
      " ______________________\n",
      "As another option, the President’s choice original soy veggie burger is great, but the PC knockoff beyond meat is weird, tastes like TVP (very bland) and turns yellow when you cook it.\n",
      " ______________________\n",
      "But hey you can get a Junior burger at Harvey's for 2$, fill that up with all the veggies and there you have your good food you broke boy.\n",
      "\n",
      "Just kidding.\n",
      "\n",
      "All jokes aside eating well at home is becoming harder by the day. The price of good stuff goes up but the price of average stuff stagnates.\n",
      " ______________________\n",
      "“This burger isn’t even made from an animal and you still butchered it!”\n",
      "\n",
      "-Future Gordon Ramsay\n",
      " ______________________\n",
      "Although I'm interested in trying these on the bbq the MSRP of $7.49-7.99 for a pack of two 4oz burgers seems steep.\n",
      " ______________________\n",
      "I'm all for cutting down meat consumption, but food processed in such a way to resemble burgers/sausages/etc. can't be good for you.\n",
      " ______________________\n",
      "Tim Horton’s food is terrible. Those sandwiches are awful. I don’t see how a shitty burger will ruin them.\n",
      " ______________________\n",
      "The only issue with this story here is that it is a local event and tax law people say a charity cannot give human resources or resources to a political party or political entity or they could be in violation of income tax laws. The minister simply invited people to his event which was a local event. That means it has the freedom to have anyone there even those that you do know as local as they are for casual purposes. It is on WE if they forced people to attend an event for partisan reasons. For me, they have done many things which are eye-opening. Morneau may have told in the background people to attend and got an email from Kielburger, but I don't delve into conspiracies. People that sign NDAs should adhere to them or risk being sued.\n",
      " ______________________\n",
      "How are they cooking burgers with only a toaster and a microwave in the kitchen?\n",
      " ______________________\n",
      "Not my thing at all - but they seem to have struck the right chord in marketing.  \n",
      "\n",
      "&gt; \"Whether you're a hardcore carnivore or a strict vegan, you should be able to have our burgers, enjoy what you're eating and feel great afterward,\" said Brown, Beyond Meat's CEO.\n",
      "\n",
      "That's how you stay in your lane and don't produce backlash.\n",
      " ______________________\n",
      "I used to really like Harvey’s back in the 90s and 2000s. They closed a lot of locations in Ontario in the early 2000s, but luckily for me there was an on-campus location where I went to university.\n",
      "\n",
      "I haven’t been to one in ages. They’re almost nonexistent in the Vancouver area. A&amp;W and White Spot basically have the burger market cornered.\n",
      " ______________________\n",
      "k I read that as Five Guys  \n",
      "\n",
      "\n",
      "Like man I figured all that burger money was helping them diversify into intelligence services\n",
      " ______________________\n",
      "Ironic choice of words, since no butchering is actually going in to these burgers\n",
      "\n",
      "Can't argue with the sentiment though\n",
      " ______________________\n",
      "I actually made the dijon comparison to my bf yesterday (who is neither a big trudeau fan nor a big obama fan) and he said \"But who puts mustard on a burger, really?\" and then we walked to A&amp;W where they are currently featuring a bison burger with grainy mustard. It was a glorious coincidence. The burger was delicious.\n",
      " ______________________\n"
     ]
    }
   ],
   "source": [
    "mask=X_train.str.contains(\"burger\")\n",
    "\n",
    "for cmt in X_train[mask]:\n",
    "    print(cmt+\"\\n ______________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_processed</th>\n",
       "      <th>canada_prob</th>\n",
       "      <th>ogft_prob</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17385</th>\n",
       "      <td>First order of business, eliminate the cheeseb...</td>\n",
       "      <td>0.623524</td>\n",
       "      <td>0.376476</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>I’m the opposite, I use regular ground beef an...</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16095</th>\n",
       "      <td>Tim Horton's was my first job too :)   Not sur...</td>\n",
       "      <td>0.994089</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16104</th>\n",
       "      <td>It shocks me that anyone would eat at Tim Hort...</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>People get veggie burgers from supermarkets. S...</td>\n",
       "      <td>0.992743</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>And the inevitable and necessary drop in servi...</td>\n",
       "      <td>0.878653</td>\n",
       "      <td>0.121347</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>real people: people that goto \"Fordfest\" for a...</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>r/onguardforthee</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13811</th>\n",
       "      <td>I went to one last week and the Angus burger t...</td>\n",
       "      <td>0.996758</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>r/canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body_processed  canada_prob  \\\n",
       "17385  First order of business, eliminate the cheeseb...     0.623524   \n",
       "15938  I’m the opposite, I use regular ground beef an...     0.990242   \n",
       "16095  Tim Horton's was my first job too :)   Not sur...     0.994089   \n",
       "16104  It shocks me that anyone would eat at Tim Hort...     0.999866   \n",
       "2153   People get veggie burgers from supermarkets. S...     0.992743   \n",
       "6767   And the inevitable and necessary drop in servi...     0.878653   \n",
       "6795   real people: people that goto \"Fordfest\" for a...     0.981132   \n",
       "13811  I went to one last week and the Angus burger t...     0.996758   \n",
       "\n",
       "       ogft_prob         subreddit  y_pred  y_true  correct  \n",
       "17385   0.376476          r/canada       0       0     True  \n",
       "15938   0.009758          r/canada       0       0     True  \n",
       "16095   0.005911          r/canada       0       0     True  \n",
       "16104   0.000134          r/canada       0       0     True  \n",
       "2153    0.007257  r/onguardforthee       0       1    False  \n",
       "6767    0.121347  r/onguardforthee       0       1    False  \n",
       "6795    0.018868  r/onguardforthee       0       1    False  \n",
       "13811   0.003242          r/canada       0       0     True  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=comment_probs['body_processed'].str.contains(\"burger\")\n",
    "\n",
    "comment_probs[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burger chat was classified with an accuracy of 0.625%, so maybe it's on to something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/OnGuardForThee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogft_count</th>\n",
       "      <th>canada_count</th>\n",
       "      <th>ogft_log_prob</th>\n",
       "      <th>canada_log_prob</th>\n",
       "      <th>odds_gap</th>\n",
       "      <th>favoured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metacanada</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.776757</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>4.143498</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leftist</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.501653</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>3.418602</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onguardforthe</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.991201</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.929054</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.984397</td>\n",
       "      <td>-7.533961</td>\n",
       "      <td>2.549564</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canadapolit</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.450734</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.469522</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gavin</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.537745</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.382510</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brigad</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.537745</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.382510</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denier</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.287200</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levant</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.287200</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialist</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.603436</td>\n",
       "      <td>-7.821643</td>\n",
       "      <td>2.218207</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intoler</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.738416</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.181840</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gop</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.738416</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.181840</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lick</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.738416</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.181840</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dougi</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.738416</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.181840</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atheist</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.738416</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.181840</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alabama</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.738416</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>2.181840</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewpoint</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.102427</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>2.124681</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigot</th>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.197971</td>\n",
       "      <td>-7.310818</td>\n",
       "      <td>2.112847</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passion</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.227590</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.999518</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andi</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.227590</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.999518</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misogynist</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.296583</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.930525</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmp</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.989730</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>1.930525</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcinn</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.989730</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>1.930525</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misogyni</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.296583</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.930525</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alt</th>\n",
       "      <td>61.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-4.808506</td>\n",
       "      <td>-6.723031</td>\n",
       "      <td>1.914525</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow</th>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.222068</td>\n",
       "      <td>-7.128496</td>\n",
       "      <td>1.906428</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redneck</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.370691</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.856417</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jewish</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.370691</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.856417</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incel</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.991201</td>\n",
       "      <td>-7.821643</td>\n",
       "      <td>1.830442</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peterson</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.534443</td>\n",
       "      <td>-7.310818</td>\n",
       "      <td>1.776375</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tori</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.534443</td>\n",
       "      <td>-7.310818</td>\n",
       "      <td>1.776375</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harbour</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.143881</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>1.776375</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.143881</td>\n",
       "      <td>-8.920255</td>\n",
       "      <td>1.776375</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vest</th>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.222068</td>\n",
       "      <td>-6.974345</td>\n",
       "      <td>1.752277</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shithol</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.537745</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.689363</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.537745</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.689363</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shill</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.537745</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.689363</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jordan</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.163052</td>\n",
       "      <td>-7.821643</td>\n",
       "      <td>1.658592</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denial</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.163052</td>\n",
       "      <td>-7.821643</td>\n",
       "      <td>1.658592</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maga</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.163052</td>\n",
       "      <td>-7.821643</td>\n",
       "      <td>1.658592</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.892589</td>\n",
       "      <td>-6.522360</td>\n",
       "      <td>1.629771</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republican</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.352121</td>\n",
       "      <td>-6.974345</td>\n",
       "      <td>1.622224</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rabbit</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadow</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conscious</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persecut</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allianc</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>museum</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.633055</td>\n",
       "      <td>-8.227108</td>\n",
       "      <td>1.594053</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ogft_count  canada_count  ogft_log_prob  canada_log_prob  \\\n",
       "token                                                                     \n",
       "metacanada           63.0           0.0      -4.776757        -8.920255   \n",
       "leftist              30.0           0.0      -5.501653        -8.920255   \n",
       "onguardforthe        18.0           0.0      -5.991201        -8.920255   \n",
       "mod                  51.0           3.0      -4.984397        -7.533961   \n",
       "canadapolit          11.0           0.0      -6.450734        -8.920255   \n",
       "gavin                10.0           0.0      -6.537745        -8.920255   \n",
       "brigad               10.0           0.0      -6.537745        -8.920255   \n",
       "denier                9.0           0.0      -6.633055        -8.920255   \n",
       "levant                9.0           0.0      -6.633055        -8.920255   \n",
       "socialist            27.0           2.0      -5.603436        -7.821643   \n",
       "intoler               8.0           0.0      -6.738416        -8.920255   \n",
       "gop                   8.0           0.0      -6.738416        -8.920255   \n",
       "lick                  8.0           0.0      -6.738416        -8.920255   \n",
       "dougi                 8.0           0.0      -6.738416        -8.920255   \n",
       "atheist               8.0           0.0      -6.738416        -8.920255   \n",
       "alabama               8.0           0.0      -6.738416        -8.920255   \n",
       "viewpoint            16.0           1.0      -6.102427        -8.227108   \n",
       "bigot                41.0           4.0      -5.197971        -7.310818   \n",
       "passion              14.0           1.0      -6.227590        -8.227108   \n",
       "andi                 14.0           1.0      -6.227590        -8.227108   \n",
       "misogynist           13.0           1.0      -6.296583        -8.227108   \n",
       "mmp                   6.0           0.0      -6.989730        -8.920255   \n",
       "mcinn                 6.0           0.0      -6.989730        -8.920255   \n",
       "misogyni             13.0           1.0      -6.296583        -8.227108   \n",
       "alt                  61.0           8.0      -4.808506        -6.723031   \n",
       "yellow               40.0           5.0      -5.222068        -7.128496   \n",
       "redneck              12.0           1.0      -6.370691        -8.227108   \n",
       "jewish               12.0           1.0      -6.370691        -8.227108   \n",
       "incel                18.0           2.0      -5.991201        -7.821643   \n",
       "peterson             29.0           4.0      -5.534443        -7.310818   \n",
       "tori                 29.0           4.0      -5.534443        -7.310818   \n",
       "harbour               5.0           0.0      -7.143881        -8.920255   \n",
       "string                5.0           0.0      -7.143881        -8.920255   \n",
       "vest                 40.0           6.0      -5.222068        -6.974345   \n",
       "shithol              10.0           1.0      -6.537745        -8.227108   \n",
       "forgotten            10.0           1.0      -6.537745        -8.227108   \n",
       "shill                10.0           1.0      -6.537745        -8.227108   \n",
       "jordan               15.0           2.0      -6.163052        -7.821643   \n",
       "denial               15.0           2.0      -6.163052        -7.821643   \n",
       "maga                 15.0           2.0      -6.163052        -7.821643   \n",
       "subreddit            56.0          10.0      -4.892589        -6.522360   \n",
       "republican           35.0           6.0      -5.352121        -6.974345   \n",
       "rabbit                9.0           1.0      -6.633055        -8.227108   \n",
       "shadow                9.0           1.0      -6.633055        -8.227108   \n",
       "conscious             9.0           1.0      -6.633055        -8.227108   \n",
       "persecut              9.0           1.0      -6.633055        -8.227108   \n",
       "rag                   9.0           1.0      -6.633055        -8.227108   \n",
       "allianc               9.0           1.0      -6.633055        -8.227108   \n",
       "museum                9.0           1.0      -6.633055        -8.227108   \n",
       "contrast              9.0           1.0      -6.633055        -8.227108   \n",
       "\n",
       "               odds_gap          favoured  \n",
       "token                                      \n",
       "metacanada     4.143498  r/OnGuardForThee  \n",
       "leftist        3.418602  r/OnGuardForThee  \n",
       "onguardforthe  2.929054  r/OnGuardForThee  \n",
       "mod            2.549564  r/OnGuardForThee  \n",
       "canadapolit    2.469522  r/OnGuardForThee  \n",
       "gavin          2.382510  r/OnGuardForThee  \n",
       "brigad         2.382510  r/OnGuardForThee  \n",
       "denier         2.287200  r/OnGuardForThee  \n",
       "levant         2.287200  r/OnGuardForThee  \n",
       "socialist      2.218207  r/OnGuardForThee  \n",
       "intoler        2.181840  r/OnGuardForThee  \n",
       "gop            2.181840  r/OnGuardForThee  \n",
       "lick           2.181840  r/OnGuardForThee  \n",
       "dougi          2.181840  r/OnGuardForThee  \n",
       "atheist        2.181840  r/OnGuardForThee  \n",
       "alabama        2.181840  r/OnGuardForThee  \n",
       "viewpoint      2.124681  r/OnGuardForThee  \n",
       "bigot          2.112847  r/OnGuardForThee  \n",
       "passion        1.999518  r/OnGuardForThee  \n",
       "andi           1.999518  r/OnGuardForThee  \n",
       "misogynist     1.930525  r/OnGuardForThee  \n",
       "mmp            1.930525  r/OnGuardForThee  \n",
       "mcinn          1.930525  r/OnGuardForThee  \n",
       "misogyni       1.930525  r/OnGuardForThee  \n",
       "alt            1.914525  r/OnGuardForThee  \n",
       "yellow         1.906428  r/OnGuardForThee  \n",
       "redneck        1.856417  r/OnGuardForThee  \n",
       "jewish         1.856417  r/OnGuardForThee  \n",
       "incel          1.830442  r/OnGuardForThee  \n",
       "peterson       1.776375  r/OnGuardForThee  \n",
       "tori           1.776375  r/OnGuardForThee  \n",
       "harbour        1.776375  r/OnGuardForThee  \n",
       "string         1.776375  r/OnGuardForThee  \n",
       "vest           1.752277  r/OnGuardForThee  \n",
       "shithol        1.689363  r/OnGuardForThee  \n",
       "forgotten      1.689363  r/OnGuardForThee  \n",
       "shill          1.689363  r/OnGuardForThee  \n",
       "jordan         1.658592  r/OnGuardForThee  \n",
       "denial         1.658592  r/OnGuardForThee  \n",
       "maga           1.658592  r/OnGuardForThee  \n",
       "subreddit      1.629771  r/OnGuardForThee  \n",
       "republican     1.622224  r/OnGuardForThee  \n",
       "rabbit         1.594053  r/OnGuardForThee  \n",
       "shadow         1.594053  r/OnGuardForThee  \n",
       "conscious      1.594053  r/OnGuardForThee  \n",
       "persecut       1.594053  r/OnGuardForThee  \n",
       "rag            1.594053  r/OnGuardForThee  \n",
       "allianc        1.594053  r/OnGuardForThee  \n",
       "museum         1.594053  r/OnGuardForThee  \n",
       "contrast       1.594053  r/OnGuardForThee  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_probs[token_probs['favoured']=='r/OnGuardForThee'].sort_values('odds_gap', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most skewed token for r/OGFT is **metacanada**. This is the name of an alt-right Canadian subreddit. In general, this list is full of tokens related to metacommentary about other aspects of reddit. \"onguardforthe\", \"mod\", \"canadapolit\", and \"subreddit\" are all tokens related to commentary on reddit itself, or other reddit communities.\n",
    "\n",
    "Without exception, ever token on this list that's related to a person's name is a loud, online conservative media commentator. \"levant\" (Ezra Levant), \"gavin\" \"mcinn\" (Gavin McInnes), \"jordan\" \"peterson\" (Jordan Peterson).\n",
    "\n",
    "Loaded language that's characteristic of leftist online social discussion. \"denier/denial\", \"bigot\", \"intoler\", \"lick\" (typically as in bootlicker), \"misognyis/misogynist\", \"shill\", \"rag\", \"redneck\", \"incel\".\n",
    "\n",
    "Left wing keywords like \"leftist\" and \"socialist\".\n",
    "\n",
    "References to conservative groups: \"maga\", \"republican\", \"yellow\", \"vest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the model is pretty sure that if you're criticizing/discussing some other subreddit or conservative group, you're probably making an r/OnGuardForThee post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Keywords complaining about conservative issues takes up far more of this leaderboard than tokens relating to leftist policy. So does meta-discussion about more right wing Canadian subreddits. This could be evidence towards the pretty common anecdotal complaint that online left wing discussion spends more time hate reading/discussing things they don't like than on policy goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are kind of outliers, though. Many of these are words that just weren't seen in the comment set of one subreddit or the other. What about more common words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewed Common Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at tokens with a large odds gap that appeared in at least 100 comments in each subreddit in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogft_count</th>\n",
       "      <th>canada_count</th>\n",
       "      <th>ogft_log_prob</th>\n",
       "      <th>canada_log_prob</th>\n",
       "      <th>odds_gap</th>\n",
       "      <th>favoured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>111.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-4.217141</td>\n",
       "      <td>-3.699900</td>\n",
       "      <td>0.517242</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hous</th>\n",
       "      <td>101.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-4.310668</td>\n",
       "      <td>-3.826505</td>\n",
       "      <td>0.484162</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>128.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-4.075828</td>\n",
       "      <td>-3.662760</td>\n",
       "      <td>0.413068</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>102.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-4.300911</td>\n",
       "      <td>-3.896375</td>\n",
       "      <td>0.404536</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compani</th>\n",
       "      <td>146.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-3.945208</td>\n",
       "      <td>-3.657565</td>\n",
       "      <td>0.287643</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>130.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-4.060443</td>\n",
       "      <td>-3.778592</td>\n",
       "      <td>0.281851</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>139.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-3.993998</td>\n",
       "      <td>-3.732870</td>\n",
       "      <td>0.261128</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>law</th>\n",
       "      <td>170.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>-3.793977</td>\n",
       "      <td>-3.535760</td>\n",
       "      <td>0.258216</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>106.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-4.262811</td>\n",
       "      <td>-4.007601</td>\n",
       "      <td>0.255211</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legal</th>\n",
       "      <td>122.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-4.123456</td>\n",
       "      <td>-3.870399</td>\n",
       "      <td>0.253057</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>266.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>-3.348392</td>\n",
       "      <td>-3.118137</td>\n",
       "      <td>0.230255</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>233.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>-3.480319</td>\n",
       "      <td>-3.250374</td>\n",
       "      <td>0.229945</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>less</th>\n",
       "      <td>167.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-3.811676</td>\n",
       "      <td>-3.602135</td>\n",
       "      <td>0.209541</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>132.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-4.045291</td>\n",
       "      <td>-3.838851</td>\n",
       "      <td>0.206440</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>133.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-4.037801</td>\n",
       "      <td>-3.838851</td>\n",
       "      <td>0.198949</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>168.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-3.805742</td>\n",
       "      <td>-3.616951</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>450.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>-2.824173</td>\n",
       "      <td>-2.641734</td>\n",
       "      <td>0.182439</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>509.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>-2.701230</td>\n",
       "      <td>-2.548644</td>\n",
       "      <td>0.152586</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next</th>\n",
       "      <td>130.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-4.060443</td>\n",
       "      <td>-3.909620</td>\n",
       "      <td>0.150823</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>140.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-3.986880</td>\n",
       "      <td>-3.845082</td>\n",
       "      <td>0.141799</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>126.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-4.091453</td>\n",
       "      <td>-3.950442</td>\n",
       "      <td>0.141011</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay</th>\n",
       "      <td>280.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>-3.297286</td>\n",
       "      <td>-3.161354</td>\n",
       "      <td>0.135932</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>206.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>-3.602922</td>\n",
       "      <td>-3.469217</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anoth</th>\n",
       "      <td>127.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-4.083610</td>\n",
       "      <td>-3.950442</td>\n",
       "      <td>0.133168</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>govern</th>\n",
       "      <td>408.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>-2.921925</td>\n",
       "      <td>-2.795572</td>\n",
       "      <td>0.126353</td>\n",
       "      <td>r/Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ogft_count  canada_count  ogft_log_prob  canada_log_prob  odds_gap  \\\n",
       "token                                                                         \n",
       "buy           111.0         184.0      -4.217141        -3.699900  0.517242   \n",
       "hous          101.0         162.0      -4.310668        -3.826505  0.484162   \n",
       "cost          128.0         191.0      -4.075828        -3.662760  0.413068   \n",
       "month         102.0         151.0      -4.300911        -3.896375  0.404536   \n",
       "compani       146.0         192.0      -3.945208        -3.657565  0.287643   \n",
       "home          130.0         170.0      -4.060443        -3.778592  0.281851   \n",
       "ask           139.0         178.0      -3.993998        -3.732870  0.261128   \n",
       "law           170.0         217.0      -3.793977        -3.535760  0.258216   \n",
       "lol           106.0         135.0      -4.262811        -4.007601  0.255211   \n",
       "legal         122.0         155.0      -4.123456        -3.870399  0.253057   \n",
       "money         266.0         330.0      -3.348392        -3.118137  0.230255   \n",
       "day           233.0         289.0      -3.480319        -3.250374  0.229945   \n",
       "less          167.0         203.0      -3.811676        -3.602135  0.209541   \n",
       "big           132.0         160.0      -4.045291        -3.838851  0.206440   \n",
       "case          133.0         160.0      -4.037801        -3.838851  0.198949   \n",
       "yes           168.0         200.0      -3.805742        -3.616951  0.188791   \n",
       "year          450.0         532.0      -2.824173        -2.641734  0.182439   \n",
       "time          509.0         584.0      -2.701230        -2.548644  0.152586   \n",
       "next          130.0         149.0      -4.060443        -3.909620  0.150823   \n",
       "great         140.0         159.0      -3.986880        -3.845082  0.141799   \n",
       "may           126.0         143.0      -4.091453        -3.950442  0.141011   \n",
       "pay           280.0         316.0      -3.297286        -3.161354  0.135932   \n",
       "tax           206.0         232.0      -3.602922        -3.469217  0.133705   \n",
       "anoth         127.0         143.0      -4.083610        -3.950442  0.133168   \n",
       "govern        408.0         456.0      -2.921925        -2.795572  0.126353   \n",
       "\n",
       "         favoured  \n",
       "token              \n",
       "buy      r/Canada  \n",
       "hous     r/Canada  \n",
       "cost     r/Canada  \n",
       "month    r/Canada  \n",
       "compani  r/Canada  \n",
       "home     r/Canada  \n",
       "ask      r/Canada  \n",
       "law      r/Canada  \n",
       "lol      r/Canada  \n",
       "legal    r/Canada  \n",
       "money    r/Canada  \n",
       "day      r/Canada  \n",
       "less     r/Canada  \n",
       "big      r/Canada  \n",
       "case     r/Canada  \n",
       "yes      r/Canada  \n",
       "year     r/Canada  \n",
       "time     r/Canada  \n",
       "next     r/Canada  \n",
       "great    r/Canada  \n",
       "may      r/Canada  \n",
       "pay      r/Canada  \n",
       "tax      r/Canada  \n",
       "anoth    r/Canada  \n",
       "govern   r/Canada  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=(token_probs['favoured']=='r/Canada') & (token_probs['ogft_count'] >= 100) & (token_probs['canada_count'] >= 100)\n",
    "\n",
    "token_probs[mask].sort_values('odds_gap', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common economic words seem to be more strongly weighted to r/Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogft_count</th>\n",
       "      <th>canada_count</th>\n",
       "      <th>ogft_log_prob</th>\n",
       "      <th>canada_log_prob</th>\n",
       "      <th>odds_gap</th>\n",
       "      <th>favoured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conserv</th>\n",
       "      <td>507.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-2.705159</td>\n",
       "      <td>-3.784457</td>\n",
       "      <td>1.079298</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>401.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>-2.939188</td>\n",
       "      <td>-3.673231</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elect</th>\n",
       "      <td>293.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-3.252061</td>\n",
       "      <td>-3.838851</td>\n",
       "      <td>0.586790</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>187.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-3.699198</td>\n",
       "      <td>-4.275865</td>\n",
       "      <td>0.576666</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>242.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-3.442579</td>\n",
       "      <td>-3.936649</td>\n",
       "      <td>0.494070</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>168.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-3.805742</td>\n",
       "      <td>-4.285526</td>\n",
       "      <td>0.479785</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liber</th>\n",
       "      <td>294.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-3.248665</td>\n",
       "      <td>-3.721758</td>\n",
       "      <td>0.473093</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>175.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-3.765156</td>\n",
       "      <td>-4.228908</td>\n",
       "      <td>0.463751</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>267.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-3.344653</td>\n",
       "      <td>-3.808268</td>\n",
       "      <td>0.463614</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polit</th>\n",
       "      <td>300.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>-3.228530</td>\n",
       "      <td>-3.689147</td>\n",
       "      <td>0.460617</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parti</th>\n",
       "      <td>317.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-3.173589</td>\n",
       "      <td>-3.631988</td>\n",
       "      <td>0.458399</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alberta</th>\n",
       "      <td>201.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-3.627373</td>\n",
       "      <td>-4.029906</td>\n",
       "      <td>0.402534</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>707.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>-2.373196</td>\n",
       "      <td>-2.769653</td>\n",
       "      <td>0.396456</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>184.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-3.715285</td>\n",
       "      <td>-4.108071</td>\n",
       "      <td>0.392787</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kind</th>\n",
       "      <td>170.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>-3.793977</td>\n",
       "      <td>-4.184057</td>\n",
       "      <td>0.390080</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alway</th>\n",
       "      <td>196.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-3.652437</td>\n",
       "      <td>-4.029906</td>\n",
       "      <td>0.377470</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>300.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-3.228530</td>\n",
       "      <td>-3.602135</td>\n",
       "      <td>0.373605</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>believ</th>\n",
       "      <td>212.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-3.574348</td>\n",
       "      <td>-3.943522</td>\n",
       "      <td>0.369174</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment</th>\n",
       "      <td>182.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-3.726154</td>\n",
       "      <td>-4.091942</td>\n",
       "      <td>0.365787</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>178.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>-3.748255</td>\n",
       "      <td>-4.099974</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>145.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-3.952034</td>\n",
       "      <td>-4.295283</td>\n",
       "      <td>0.343249</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ontario</th>\n",
       "      <td>190.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-3.683367</td>\n",
       "      <td>-4.022416</td>\n",
       "      <td>0.339049</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>224.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>-3.519540</td>\n",
       "      <td>-3.832659</td>\n",
       "      <td>0.313119</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>322.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>-3.157988</td>\n",
       "      <td>-3.460670</td>\n",
       "      <td>0.302682</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provinc</th>\n",
       "      <td>162.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-3.841890</td>\n",
       "      <td>-4.124465</td>\n",
       "      <td>0.282575</td>\n",
       "      <td>r/OnGuardForThee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ogft_count  canada_count  ogft_log_prob  canada_log_prob  odds_gap  \\\n",
       "token                                                                         \n",
       "conserv       507.0         169.0      -2.705159        -3.784457  1.079298   \n",
       "vote          401.0         189.0      -2.939188        -3.673231  0.734043   \n",
       "elect         293.0         160.0      -3.252061        -3.838851  0.586790   \n",
       "left          187.0         103.0      -3.699198        -4.275865  0.576666   \n",
       "post          242.0         145.0      -3.442579        -3.936649  0.494070   \n",
       "power         168.0         102.0      -3.805742        -4.285526  0.479785   \n",
       "liber         294.0         180.0      -3.248665        -3.721758  0.473093   \n",
       "social        175.0         108.0      -3.765156        -4.228908  0.463751   \n",
       "support       267.0         165.0      -3.344653        -3.808268  0.463614   \n",
       "polit         300.0         186.0      -3.228530        -3.689147  0.460617   \n",
       "parti         317.0         197.0      -3.173589        -3.631988  0.458399   \n",
       "alberta       201.0         132.0      -3.627373        -4.029906  0.402534   \n",
       "right         707.0         468.0      -2.373196        -2.769653  0.396456   \n",
       "news          184.0         122.0      -3.715285        -4.108071  0.392787   \n",
       "kind          170.0         113.0      -3.793977        -4.184057  0.390080   \n",
       "alway         196.0         132.0      -3.652437        -4.029906  0.377470   \n",
       "shit          300.0         203.0      -3.228530        -3.602135  0.373605   \n",
       "believ        212.0         144.0      -3.574348        -3.943522  0.369174   \n",
       "comment       182.0         124.0      -3.726154        -4.091942  0.365787   \n",
       "https         178.0         123.0      -3.748255        -4.099974  0.351719   \n",
       "old           145.0         101.0      -3.952034        -4.295283  0.343249   \n",
       "ontario       190.0         133.0      -3.683367        -4.022416  0.339049   \n",
       "feel          224.0         161.0      -3.519540        -3.832659  0.313119   \n",
       "person        322.0         234.0      -3.157988        -3.460670  0.302682   \n",
       "provinc       162.0         120.0      -3.841890        -4.124465  0.282575   \n",
       "\n",
       "                 favoured  \n",
       "token                      \n",
       "conserv  r/OnGuardForThee  \n",
       "vote     r/OnGuardForThee  \n",
       "elect    r/OnGuardForThee  \n",
       "left     r/OnGuardForThee  \n",
       "post     r/OnGuardForThee  \n",
       "power    r/OnGuardForThee  \n",
       "liber    r/OnGuardForThee  \n",
       "social   r/OnGuardForThee  \n",
       "support  r/OnGuardForThee  \n",
       "polit    r/OnGuardForThee  \n",
       "parti    r/OnGuardForThee  \n",
       "alberta  r/OnGuardForThee  \n",
       "right    r/OnGuardForThee  \n",
       "news     r/OnGuardForThee  \n",
       "kind     r/OnGuardForThee  \n",
       "alway    r/OnGuardForThee  \n",
       "shit     r/OnGuardForThee  \n",
       "believ   r/OnGuardForThee  \n",
       "comment  r/OnGuardForThee  \n",
       "https    r/OnGuardForThee  \n",
       "old      r/OnGuardForThee  \n",
       "ontario  r/OnGuardForThee  \n",
       "feel     r/OnGuardForThee  \n",
       "person   r/OnGuardForThee  \n",
       "provinc  r/OnGuardForThee  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=(token_probs['favoured']=='r/OnGuardForThee') & (token_probs['ogft_count'] >= 100) & (token_probs['canada_count'] >= 100)\n",
    "\n",
    "token_probs[mask].sort_values('odds_gap', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can see that I messed up the regex removing URL's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Other than that, we can see a stronger tendence towards specifically political/regional discussion. Lots of political keywords, lots of names of provinces.\n",
    " \n",
    "We can also see that the odds gaps for favoured OnGuardForThee words is larger than those of r/Canada. E.g., the top 50 gaps with no filter range from 4.15-1.59 , while for r/Canada they range from 2.84-1.40. Similarly, when adding a minimum token count threshold, the largest 25 gaps in favour of OnGuardForThee range from 1.08-0.28, while the largest 25 in favour of r/Canada range from 0.53-0.13.\n",
    "\n",
    "I find this interesting, because the model overall favours r/Canada -- recall that it assigned 60% of posts to r/Canada. Despite this, the keywords that are associated to be favoured by OnGuardForThee seem to be assigned a more significant weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r/OnGuardForThee    2057\n",
       "r/Canada            1943\n",
       "Name: favoured, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_probs['favoured'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's more tokens that are classified as more strongly weighted for OnGuardForThee, too! However, now let's look at some statistics aggregated by sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogft_count</th>\n",
       "      <th>canada_count</th>\n",
       "      <th>ogft_log_prob</th>\n",
       "      <th>canada_log_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favoured</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r/Canada</th>\n",
       "      <td>43704.0</td>\n",
       "      <td>55946.0</td>\n",
       "      <td>-12616.586240</td>\n",
       "      <td>-11844.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r/OnGuardForThee</th>\n",
       "      <td>77243.0</td>\n",
       "      <td>56138.0</td>\n",
       "      <td>-12151.230407</td>\n",
       "      <td>-13124.613989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ogft_count  canada_count  ogft_log_prob  canada_log_prob\n",
       "favoured                                                                  \n",
       "r/Canada             43704.0       55946.0  -12616.586240    -11844.073700\n",
       "r/OnGuardForThee     77243.0       56138.0  -12151.230407    -13124.613989"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_probs[['ogft_count','canada_count', 'ogft_log_prob', 'canada_log_prob','favoured']].groupby('favoured').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little hard to interpret (and yes, I tried histograms, but it was mostly too minute to visualize). But it appears to show that over all r/canada favoured words, the sums of the canada_log_probs are larger than the sum of the otfg log probabilities of the onguardforthee favoured tokens. That is, despite OGFT having the more noticible gaps in probability weights, the total sum of probabilities of words that skew towards r/Canada is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick Dornian\\AppData\\Roaming\\Python\\Python38\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Patrick Dornian\\AppData\\Roaming\\Python\\Python38\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Log Odds')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax=plt.subplots(figsize=(15,10))\n",
    "sns.set_theme()\n",
    "sns.distplot(token_probs['ogft_log_prob'])\n",
    "sns.distplot(token_probs['canada_log_prob'])\n",
    "ax.legend(['r\\OnGuardForThee', 'r\\Canada'])\n",
    "plt.xlabel(\"Log Odds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The final model chosen was a Bernoulli naive Bayes binary classifer, using 4000 features learned from the training set.\n",
    "\n",
    "We evaluated the model on a test set using standard classification metrics. Additionally, results were recorded for the classification performance of the test set partitioned into comments of greater than 20 words (long comments), and comments 20 or less words (short comments).\n",
    "\n",
    "|                                  | All comments | Long Comments (>20 words) | Short Comments (<=20 words) |\n",
    "|---------------------------------:|:------------:|:-------------------------:|:---------------------------:|\n",
    "|                   Total Comments |     5016     |            2822           |             2204            |\n",
    "|          Actual r/OnGuardForThee |     2533     |            1456           |             1127            |\n",
    "|                  Actual r/Canada |     2493     |            1366           |             1077            |\n",
    "|       Predicted r/OnGuardForThee |     2018     |            1443           |             575             |\n",
    "|               Predicted r/Canada |     3008     |            1337           |             1629            |\n",
    "|                   Accuracy Score |    0.6146    |           0.6389          |            0.5835           |\n",
    "|                     Recall Score |    0.5160    |           0.6456          |            0.3708           |\n",
    "|                Specificity Score |    0.7148    |           0.6318          |            0.8154           |\n",
    "| Precision (OnGuardForThee) Score |    0.6477    |           0.6514          |            0.6383           |\n",
    "|         Precision (Canada) Score |    0.5924    |           0.6258          |            0.5641           |\n",
    "|                         F1 Score |    0.5744    |           0.6485          |            0.4443           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These conclusions imply that the model would be best used for classifying long comments-- it has adequate performance within that category. \n",
    "\n",
    "The model's performance on short comments is highly skewed towards classifying things to be in r/Canada. Though it's accuracy is still above baseline, it's bias makes me recommend against using it to classify such comments.\n",
    "\n",
    "Though the model is not particularly accurate, this is an inherently messy classification subject. I think that if used heuristically and with an understanding of it's limitations, it could still prove to be a useful classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilogue \n",
    "\n",
    "Testing functions for putting this online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post=\"I hate conservatives they are dumb bithces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_final.predict([sample_post])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2481948964306757"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_final.predict_proba([sample_post])[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_post(text, model):\n",
    "    label_map=['r/Canada', 'r/OnGuardForThee']\n",
    "    post=[text]\n",
    "    prediction=model.predict([text])[0]\n",
    "    pred_text=label_map[prediction]\n",
    "    pred_prob=round(model.predict_proba([text])[0,prediction] * 100, 1)\n",
    "    return f\"The model thinks this seems like an {pred_text} post with {pred_prob}% certainty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The model thinks this is a r/OnGuardForThee post with 75.2% certainty'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_post(sample_post, bnb_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
